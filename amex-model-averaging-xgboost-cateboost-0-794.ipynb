{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/erwanchesneau/amex-model-averaging-xgboost-cateboost-0-794?scriptVersionId=104597431\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"# LOAD LIBRARIES\nimport os\nimport gc\nimport pickle\nfrom copy import deepcopy\nimport pandas as pd\nimport numpy as np # CPU libraries\nimport cudf # GPU libraries\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestClassifier\nimport xgboost as xgb\nfrom catboost import Pool, CatBoostClassifier\nprint('RAPIDS version',cudf.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T09:24:41.295932Z","iopub.execute_input":"2022-08-31T09:24:41.296464Z","iopub.status.idle":"2022-08-31T09:24:45.21016Z","shell.execute_reply.started":"2022-08-31T09:24:41.296347Z","shell.execute_reply":"2022-08-31T09:24:45.209023Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"RAPIDS version 21.10.01\n","output_type":"stream"}]},{"cell_type":"code","source":"# VERSION NAME FOR SAVED MODEL FILES\nVER = 2\n\n# TRAIN RANDOM SEED\nSEED = 42\n\n# FILL NAN VALUE\nNAN_VALUE = -127 # will fit in int8\n\n# FOLDS PER MODEL\nFOLDS = 5\n\nTRAIN_PATH = '../input/amex-data-integer-dtypes-parquet-format/train.parquet'\n\nODIR = \"/kaggle/working/echesneau/\"\nif not os.path.isdir(ODIR):\n    os.makedirs(ODIR)\n\nTRAIN_SUBSAMPLE = 1.0\n\nresult_all = pd.DataFrame(columns=['model', 'preprocessing', 'name', \\\n                                   'y_valid_pred', 'y_pred','valid_acc', 'acc'])\nresult_sum = pd.DataFrame(columns=['model', 'preprocessing', 'name', 'y_pred', 'acc'])","metadata":{"execution":{"iopub.status.busy":"2022-08-31T09:24:45.215813Z","iopub.execute_input":"2022-08-31T09:24:45.216302Z","iopub.status.idle":"2022-08-31T09:24:45.237618Z","shell.execute_reply.started":"2022-08-31T09:24:45.216251Z","shell.execute_reply":"2022-08-31T09:24:45.236614Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def read_file(path = '', usecols = None):\n    \"\"\"\n    function to load dataset\n    The function is modified frm the original one\n    The Fillna is done only during the processing\n    \"\"\"\n    # LOAD DATAFRAME\n    if usecols is not None:\n        data = cudf.read_parquet(path, columns=usecols)\n    else:\n        data = cudf.read_parquet(path)\n    # REDUCE DTYPE FOR CUSTOMER AND DATE\n    data['customer_ID'] = data['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\n    data.S_2 = cudf.to_datetime( data.S_2 )\n    print('shape of data:', data.shape)\n\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-08-31T09:24:45.241856Z","iopub.execute_input":"2022-08-31T09:24:45.244298Z","iopub.status.idle":"2022-08-31T09:24:45.253946Z","shell.execute_reply.started":"2022-08-31T09:24:45.244248Z","shell.execute_reply":"2022-08-31T09:24:45.252681Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def process_and_feature_engineer(data):\n    \"\"\"\n    function to process database\n    FEATURE ENGINEERING FROM\n    https://www.kaggle.com/code/huseyincot/amex-agg-data-how-it-created\n    \"\"\"\n    all_cols = [c for c in list(data.columns) if c not in ['customer_ID','S_2']]\n    cat_feat = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\\\n                    \"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n    num_features = [col for col in all_cols if col not in cat_feat]\n\n    test_num_agg = data.groupby(\"customer_ID\")[num_features].agg(['mean', \\\n                                                                  'std', \\\n                                                                  'min', \\\n                                                                  'max', \\\n                                                                  'last'])\n    test_num_agg.columns = ['_'.join(x) for x in test_num_agg.columns]\n\n    test_cat_agg = data.groupby(\"customer_ID\")[cat_feat].agg(['count', \\\n                                                              'last', \\\n                                                              'nunique'])\n    test_cat_agg.columns = ['_'.join(x) for x in test_cat_agg.columns]\n\n    data = cudf.concat([test_num_agg, test_cat_agg], axis=1)\n    del test_num_agg, test_cat_agg\n    data = data.fillna(NAN_VALUE)\n    print('shape after engineering', data.shape )\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-08-31T09:24:45.259681Z","iopub.execute_input":"2022-08-31T09:24:45.262123Z","iopub.status.idle":"2022-08-31T09:24:45.274253Z","shell.execute_reply.started":"2022-08-31T09:24:45.262087Z","shell.execute_reply":"2022-08-31T09:24:45.273229Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def amex_metric_mod(y_true, y_pred):\n    \"\"\"\n    function to calculate the metric of the competion\n    from https://www.kaggle.com/kyakovlev\n    and https://www.kaggle.com/competitions/amex-default-prediction/discussion/327534\n    \"\"\"\n    labels     = np.transpose(np.array([y_true, y_pred]))\n    labels     = labels[labels[:, 1].argsort()[::-1]]\n    weights    = np.where(labels[:,0]==0, 20, 1)\n    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n\n    gini = [0,0]\n    for i in [1,0]:\n        labels         = np.transpose(np.array([y_true, y_pred]))\n        labels         = labels[labels[:, i].argsort()[::-1]]\n        weight         = np.where(labels[:,0]==0, 20, 1)\n        weight_random  = np.cumsum(weight / np.sum(weight))\n        total_pos      = np.sum(labels[:, 0] *  weight)\n        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n        lorentz        = cum_pos_found / total_pos\n        gini[i]        = np.sum((lorentz - weight_random) * weight)\n\n    return 0.5 * (gini[1]/gini[0] + top_four)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T09:24:45.278928Z","iopub.execute_input":"2022-08-31T09:24:45.281827Z","iopub.status.idle":"2022-08-31T09:24:45.295144Z","shell.execute_reply.started":"2022-08-31T09:24:45.28177Z","shell.execute_reply":"2022-08-31T09:24:45.294094Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# @huseyincot preprocessing","metadata":{}},{"cell_type":"markdown","source":"The processing proposed by @Huyseioncot seems to be interessting and it is one of the most used.\nSo we decide to base the predictions on this processing.","metadata":{}},{"cell_type":"markdown","source":"## Load and process","metadata":{}},{"cell_type":"markdown","source":"Parquet format is use to save GPU/RAM memory.","metadata":{}},{"cell_type":"code","source":"print('Reading train data...')\ntrain = read_file(path = TRAIN_PATH)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T09:24:45.299511Z","iopub.execute_input":"2022-08-31T09:24:45.303227Z","iopub.status.idle":"2022-08-31T09:25:07.462514Z","shell.execute_reply.started":"2022-08-31T09:24:45.303194Z","shell.execute_reply":"2022-08-31T09:25:07.461347Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Reading train data...\nshape of data: (5531451, 190)\n","output_type":"stream"}]},{"cell_type":"code","source":"train = process_and_feature_engineer(train)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T09:25:07.467308Z","iopub.execute_input":"2022-08-31T09:25:07.467682Z","iopub.status.idle":"2022-08-31T09:25:09.692629Z","shell.execute_reply.started":"2022-08-31T09:25:07.46764Z","shell.execute_reply":"2022-08-31T09:25:09.691486Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"shape after engineering (458913, 918)\n","output_type":"stream"}]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T09:25:09.695229Z","iopub.execute_input":"2022-08-31T09:25:09.695702Z","iopub.status.idle":"2022-08-31T09:25:10.367209Z","shell.execute_reply.started":"2022-08-31T09:25:09.695663Z","shell.execute_reply":"2022-08-31T09:25:10.366224Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                      P_2_mean   P_2_std   P_2_min   P_2_max  P_2_last  \\\ncustomer_ID                                                              \n-9223358381327749917  0.415868  0.057145  0.340178  0.498727  0.387708   \n-9223193039457028513  0.974068  0.013094  0.964483  1.002478  1.001372   \n-9223189665817919541  0.802447  0.038025  0.694073  0.828761  0.694073   \n-9223188534444851899  0.791203  0.002688  0.786647  0.794826  0.787945   \n-9223173911659837606  0.115666  0.078554  0.038207  0.252421  0.040486   \n\n                      D_39_mean  D_39_std  D_39_min  D_39_max  D_39_last  ...  \\\ncustomer_ID                                                               ...   \n-9223358381327749917   2.615385  4.628507         0        16          0  ...   \n-9223193039457028513   0.000000  0.000000         0         0          0  ...   \n-9223189665817919541   0.000000  0.000000         0         0          0  ...   \n-9223188534444851899   0.000000  0.000000         0         0          0  ...   \n-9223173911659837606   4.384615  6.144625         0        17         13  ...   \n\n                      D_63_nunique  D_64_count  D_64_last  D_64_nunique  \\\ncustomer_ID                                                               \n-9223358381327749917             1          13          2             1   \n-9223193039457028513             2          13          0             1   \n-9223189665817919541             1          13          0             1   \n-9223188534444851899             1          13          3             2   \n-9223173911659837606             1          13          0             2   \n\n                      D_66_count  D_66_last  D_66_nunique  D_68_count  \\\ncustomer_ID                                                             \n-9223358381327749917          13         -1             1          13   \n-9223193039457028513          13         -1             1          13   \n-9223189665817919541          13         -1             1          13   \n-9223188534444851899          13         -1             1          13   \n-9223173911659837606          13         -1             1          13   \n\n                      D_68_last  D_68_nunique  \ncustomer_ID                                    \n-9223358381327749917          3             2  \n-9223193039457028513          6             1  \n-9223189665817919541          6             1  \n-9223188534444851899          5             1  \n-9223173911659837606          6             2  \n\n[5 rows x 918 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>P_2_mean</th>\n      <th>P_2_std</th>\n      <th>P_2_min</th>\n      <th>P_2_max</th>\n      <th>P_2_last</th>\n      <th>D_39_mean</th>\n      <th>D_39_std</th>\n      <th>D_39_min</th>\n      <th>D_39_max</th>\n      <th>D_39_last</th>\n      <th>...</th>\n      <th>D_63_nunique</th>\n      <th>D_64_count</th>\n      <th>D_64_last</th>\n      <th>D_64_nunique</th>\n      <th>D_66_count</th>\n      <th>D_66_last</th>\n      <th>D_66_nunique</th>\n      <th>D_68_count</th>\n      <th>D_68_last</th>\n      <th>D_68_nunique</th>\n    </tr>\n    <tr>\n      <th>customer_ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>-9223358381327749917</th>\n      <td>0.415868</td>\n      <td>0.057145</td>\n      <td>0.340178</td>\n      <td>0.498727</td>\n      <td>0.387708</td>\n      <td>2.615385</td>\n      <td>4.628507</td>\n      <td>0</td>\n      <td>16</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>13</td>\n      <td>2</td>\n      <td>1</td>\n      <td>13</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>13</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>-9223193039457028513</th>\n      <td>0.974068</td>\n      <td>0.013094</td>\n      <td>0.964483</td>\n      <td>1.002478</td>\n      <td>1.001372</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>13</td>\n      <td>0</td>\n      <td>1</td>\n      <td>13</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>13</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>-9223189665817919541</th>\n      <td>0.802447</td>\n      <td>0.038025</td>\n      <td>0.694073</td>\n      <td>0.828761</td>\n      <td>0.694073</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>13</td>\n      <td>0</td>\n      <td>1</td>\n      <td>13</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>13</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>-9223188534444851899</th>\n      <td>0.791203</td>\n      <td>0.002688</td>\n      <td>0.786647</td>\n      <td>0.794826</td>\n      <td>0.787945</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>13</td>\n      <td>3</td>\n      <td>2</td>\n      <td>13</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>13</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>-9223173911659837606</th>\n      <td>0.115666</td>\n      <td>0.078554</td>\n      <td>0.038207</td>\n      <td>0.252421</td>\n      <td>0.040486</td>\n      <td>4.384615</td>\n      <td>6.144625</td>\n      <td>0</td>\n      <td>17</td>\n      <td>13</td>\n      <td>...</td>\n      <td>1</td>\n      <td>13</td>\n      <td>0</td>\n      <td>2</td>\n      <td>13</td>\n      <td>-1</td>\n      <td>1</td>\n      <td>13</td>\n      <td>6</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 918 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Targets are added in the database","metadata":{}},{"cell_type":"code","source":"# ADD TARGETS\ntargets = cudf.read_csv('../input/amex-default-prediction/train_labels.csv')\ntargets['customer_ID'] = targets['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\ntargets = targets.set_index('customer_ID')\ntrain = train.merge(targets, left_index=True, right_index=True, how='left')\ntrain.target = train.target.astype('int8')\ndel targets\n\n# NEEDED TO MAKE CV DETERMINISTIC (cudf merge above randomly shuffles rows)\ntrain = train.sort_index().reset_index()\n\n# FEATURES\nFEATURES = train.columns[1:-1]\nprint(f'There are {len(FEATURES)} features!')","metadata":{"execution":{"iopub.status.busy":"2022-08-31T09:25:10.368773Z","iopub.execute_input":"2022-08-31T09:25:10.369145Z","iopub.status.idle":"2022-08-31T09:25:11.573338Z","shell.execute_reply.started":"2022-08-31T09:25:10.36911Z","shell.execute_reply":"2022-08-31T09:25:11.572288Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"There are 918 features!\n","output_type":"stream"}]},{"cell_type":"code","source":"with open(ODIR+'/all_features.pkl', 'wb') as ofile :\n    pickle.dump(FEATURES, ofile)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T09:25:11.577438Z","iopub.execute_input":"2022-08-31T09:25:11.577734Z","iopub.status.idle":"2022-08-31T09:25:11.583217Z","shell.execute_reply.started":"2022-08-31T09:25:11.577709Z","shell.execute_reply":"2022-08-31T09:25:11.582211Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Features are needed for the prediction on the test set,\nwe save it.","metadata":{}},{"cell_type":"markdown","source":"## XGBoost","metadata":{}},{"cell_type":"markdown","source":"XGBoost seems to be one of the most efficent model.","metadata":{}},{"cell_type":"code","source":"train = train.to_pandas() # free GPU memory\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T09:25:11.584506Z","iopub.execute_input":"2022-08-31T09:25:11.58542Z","iopub.status.idle":"2022-08-31T09:25:16.091317Z","shell.execute_reply.started":"2022-08-31T09:25:11.585385Z","shell.execute_reply":"2022-08-31T09:25:16.090344Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"print('XGB Version',xgb.__version__)\n\n# XGB MODEL PARAMETERS\nxgb_parms = {\n    'max_depth':4,\n    'learning_rate':0.05,\n    'subsample':0.8,\n    'colsample_bytree':0.6,\n    'eval_metric':'logloss',\n    'objective':'binary:logistic',\n    'tree_method':'gpu_hist',\n    'predictor':'gpu_predictor',\n    'random_state':SEED\n}","metadata":{"execution":{"iopub.status.busy":"2022-08-31T09:25:16.092771Z","iopub.execute_input":"2022-08-31T09:25:16.093311Z","iopub.status.idle":"2022-08-31T09:25:16.099597Z","shell.execute_reply.started":"2022-08-31T09:25:16.093259Z","shell.execute_reply":"2022-08-31T09:25:16.098613Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"XGB Version 1.6.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Beause of memory limitation, database is split into flods.\nA model is train for each fold.\nAmex metric is calculated on the validation set, train set and all fold data.\nAt the end, the global metric is calculated","metadata":{}},{"cell_type":"code","source":"oof = []\nskf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\nfor fold,(train_idx, valid_idx) in enumerate(skf.split(\n            train, train.target )):\n    print('#'*25)\n    print('### Fold',fold+1)\n    print('### Train size',len(train_idx),'Valid size',len(valid_idx))\n    print(f'### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...')\n    print('#'*25)\n    dtrain = xgb.DMatrix(data=train.loc[train_idx, FEATURES], label=train.loc[train_idx, 'target'])\n    dvalid = xgb.DMatrix(data=train.loc[valid_idx, FEATURES], label=train.loc[valid_idx, 'target'])\n    model = xgb.train(xgb_parms,\n                      dtrain=dtrain,\n                      evals=[(dtrain,'train'),(dvalid,'valid')],\n                      num_boost_round=9999,\n                      #num_boost_round=99,\n                      early_stopping_rounds=100,\n                      verbose_eval=100)\n    model.save_model(f'{ODIR}/XGB_all_features_v{VER}_fold{fold}.xgb')\n    valid_pred = model.predict(dvalid)\n    val_acc = amex_metric_mod(train.loc[valid_idx, 'target'].values, valid_pred)\n    print('Kaggle Metric on valid set =',val_acc,'\\n')\n\n    df = train.loc[valid_idx, ['customer_ID','target'] ].copy()\n    df['oof_pred'] = valid_pred\n    oof.append( df )\n\n    del dtrain, dvalid, df\n    _ = gc.collect()\n\n    dall = xgb.DMatrix(data=train[FEATURES], label=train['target'])\n    pred = model.predict(dall)\n    all_acc = amex_metric_mod(train['target'].values, pred)\n    print('Kaggle Metric on all dataset =',all_acc,'\\n')\n    result_all = result_all.append({'model' : \"XGBoost\",\n                                    'preprocessing' : \"huseyincot_all_feat\",\n                                    'name' : f'XGB_all_features_v{VER}_fold{fold}',\n                                    'y_valid_pred' : valid_pred,\n                                    'valid_acc' : val_acc,\n                                    'y_pred' : pred,\n                                    'acc' : all_acc\n                                   },\n                                   ignore_index=True\n                                  )\n    del dall, pred, valid_pred\n    _ = gc.collect()\nprint('#'*25)\noof = pd.concat(oof,axis=0,ignore_index=True).set_index('customer_ID')\nacc = amex_metric_mod(oof.target.values, oof.oof_pred.values)\nresult_sum = result_sum.append({'model' : \"XGBoost\",\n                                'preprocessing':\"huseyincot_all_feat\",\n                                'name' : \"XGBoost_huseyincot_all_feat\",\n                                'y_pred' : oof,\n                                'acc': acc\n                               },\n                               ignore_index=True\n                              )\nprint('OVERALL CV Kaggle Metric =',acc)\n\ndel oof, acc\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T09:25:16.101174Z","iopub.execute_input":"2022-08-31T09:25:16.101932Z","iopub.status.idle":"2022-08-31T09:35:58.731482Z","shell.execute_reply.started":"2022-08-31T09:25:16.101897Z","shell.execute_reply":"2022-08-31T09:35:58.730517Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"#########################\n### Fold 1\n### Train size 367130 Valid size 91783\n### Training with 100% fold data...\n#########################\n[0]\ttrain-logloss:0.66272\tvalid-logloss:0.66266\n[100]\ttrain-logloss:0.23674\tvalid-logloss:0.23923\n[200]\ttrain-logloss:0.22239\tvalid-logloss:0.22728\n[300]\ttrain-logloss:0.21634\tvalid-logloss:0.22324\n[400]\ttrain-logloss:0.21232\tvalid-logloss:0.22119\n[500]\ttrain-logloss:0.20918\tvalid-logloss:0.22006\n[600]\ttrain-logloss:0.20646\tvalid-logloss:0.21929\n[700]\ttrain-logloss:0.20401\tvalid-logloss:0.21872\n[800]\ttrain-logloss:0.20179\tvalid-logloss:0.21838\n[900]\ttrain-logloss:0.19961\tvalid-logloss:0.21806\n[1000]\ttrain-logloss:0.19754\tvalid-logloss:0.21781\n[1100]\ttrain-logloss:0.19556\tvalid-logloss:0.21760\n[1200]\ttrain-logloss:0.19357\tvalid-logloss:0.21742\n[1300]\ttrain-logloss:0.19171\tvalid-logloss:0.21734\n[1400]\ttrain-logloss:0.18988\tvalid-logloss:0.21728\n[1500]\ttrain-logloss:0.18807\tvalid-logloss:0.21721\n[1600]\ttrain-logloss:0.18628\tvalid-logloss:0.21712\n[1700]\ttrain-logloss:0.18459\tvalid-logloss:0.21709\n[1800]\ttrain-logloss:0.18293\tvalid-logloss:0.21705\n[1899]\ttrain-logloss:0.18128\tvalid-logloss:0.21707\nKaggle Metric on valid set = 0.7923028981785427 \n\nKaggle Metric on all dataset = 0.8429659071452711 \n\n#########################\n### Fold 2\n### Train size 367130 Valid size 91783\n### Training with 100% fold data...\n#########################\n[0]\ttrain-logloss:0.66273\tvalid-logloss:0.66265\n[100]\ttrain-logloss:0.23715\tvalid-logloss:0.23785\n[200]\ttrain-logloss:0.22284\tvalid-logloss:0.22577\n[300]\ttrain-logloss:0.21671\tvalid-logloss:0.22187\n[400]\ttrain-logloss:0.21263\tvalid-logloss:0.21989\n[500]\ttrain-logloss:0.20950\tvalid-logloss:0.21873\n[600]\ttrain-logloss:0.20677\tvalid-logloss:0.21803\n[700]\ttrain-logloss:0.20434\tvalid-logloss:0.21749\n[800]\ttrain-logloss:0.20198\tvalid-logloss:0.21704\n[900]\ttrain-logloss:0.19975\tvalid-logloss:0.21677\n[1000]\ttrain-logloss:0.19765\tvalid-logloss:0.21658\n[1100]\ttrain-logloss:0.19564\tvalid-logloss:0.21633\n[1200]\ttrain-logloss:0.19376\tvalid-logloss:0.21622\n[1300]\ttrain-logloss:0.19189\tvalid-logloss:0.21615\n[1400]\ttrain-logloss:0.19004\tvalid-logloss:0.21615\n[1500]\ttrain-logloss:0.18819\tvalid-logloss:0.21609\n[1600]\ttrain-logloss:0.18646\tvalid-logloss:0.21606\n[1700]\ttrain-logloss:0.18466\tvalid-logloss:0.21598\n[1752]\ttrain-logloss:0.18379\tvalid-logloss:0.21598\nKaggle Metric on valid set = 0.7926375314496539 \n\nKaggle Metric on all dataset = 0.8391523394831826 \n\n#########################\n### Fold 3\n### Train size 367130 Valid size 91783\n### Training with 100% fold data...\n#########################\n[0]\ttrain-logloss:0.66267\tvalid-logloss:0.66281\n[100]\ttrain-logloss:0.23642\tvalid-logloss:0.24050\n[200]\ttrain-logloss:0.22218\tvalid-logloss:0.22872\n[300]\ttrain-logloss:0.21606\tvalid-logloss:0.22474\n[400]\ttrain-logloss:0.21208\tvalid-logloss:0.22293\n[500]\ttrain-logloss:0.20885\tvalid-logloss:0.22176\n[600]\ttrain-logloss:0.20610\tvalid-logloss:0.22100\n[700]\ttrain-logloss:0.20359\tvalid-logloss:0.22051\n[800]\ttrain-logloss:0.20126\tvalid-logloss:0.22014\n[900]\ttrain-logloss:0.19907\tvalid-logloss:0.21990\n[1000]\ttrain-logloss:0.19701\tvalid-logloss:0.21968\n[1100]\ttrain-logloss:0.19498\tvalid-logloss:0.21956\n[1200]\ttrain-logloss:0.19302\tvalid-logloss:0.21945\n[1300]\ttrain-logloss:0.19118\tvalid-logloss:0.21939\n[1400]\ttrain-logloss:0.18933\tvalid-logloss:0.21936\n[1500]\ttrain-logloss:0.18757\tvalid-logloss:0.21932\n[1600]\ttrain-logloss:0.18582\tvalid-logloss:0.21929\n[1700]\ttrain-logloss:0.18410\tvalid-logloss:0.21927\n[1800]\ttrain-logloss:0.18240\tvalid-logloss:0.21921\n[1900]\ttrain-logloss:0.18074\tvalid-logloss:0.21920\n[1957]\ttrain-logloss:0.17980\tvalid-logloss:0.21923\nKaggle Metric on valid set = 0.7906647706308858 \n\nKaggle Metric on all dataset = 0.8435234258602844 \n\n#########################\n### Fold 4\n### Train size 367131 Valid size 91782\n### Training with 100% fold data...\n#########################\n[0]\ttrain-logloss:0.66267\tvalid-logloss:0.66284\n[100]\ttrain-logloss:0.23640\tvalid-logloss:0.24101\n[200]\ttrain-logloss:0.22184\tvalid-logloss:0.22869\n[300]\ttrain-logloss:0.21579\tvalid-logloss:0.22502\n[400]\ttrain-logloss:0.21166\tvalid-logloss:0.22307\n[500]\ttrain-logloss:0.20850\tvalid-logloss:0.22206\n[600]\ttrain-logloss:0.20572\tvalid-logloss:0.22124\n[700]\ttrain-logloss:0.20323\tvalid-logloss:0.22072\n[800]\ttrain-logloss:0.20088\tvalid-logloss:0.22037\n[900]\ttrain-logloss:0.19872\tvalid-logloss:0.22009\n[1000]\ttrain-logloss:0.19661\tvalid-logloss:0.21994\n[1100]\ttrain-logloss:0.19457\tvalid-logloss:0.21975\n[1200]\ttrain-logloss:0.19263\tvalid-logloss:0.21967\n[1300]\ttrain-logloss:0.19074\tvalid-logloss:0.21961\n[1400]\ttrain-logloss:0.18893\tvalid-logloss:0.21952\n[1500]\ttrain-logloss:0.18717\tvalid-logloss:0.21946\n[1600]\ttrain-logloss:0.18542\tvalid-logloss:0.21950\n[1673]\ttrain-logloss:0.18416\tvalid-logloss:0.21948\nKaggle Metric on valid set = 0.7878870687695534 \n\nKaggle Metric on all dataset = 0.8373528703029521 \n\n#########################\n### Fold 5\n### Train size 367131 Valid size 91782\n### Training with 100% fold data...\n#########################\n[0]\ttrain-logloss:0.66272\tvalid-logloss:0.66266\n[100]\ttrain-logloss:0.23727\tvalid-logloss:0.23804\n[200]\ttrain-logloss:0.22293\tvalid-logloss:0.22577\n[300]\ttrain-logloss:0.21681\tvalid-logloss:0.22174\n[400]\ttrain-logloss:0.21281\tvalid-logloss:0.21970\n[500]\ttrain-logloss:0.20963\tvalid-logloss:0.21850\n[600]\ttrain-logloss:0.20695\tvalid-logloss:0.21783\n[700]\ttrain-logloss:0.20448\tvalid-logloss:0.21727\n[800]\ttrain-logloss:0.20211\tvalid-logloss:0.21681\n[900]\ttrain-logloss:0.19987\tvalid-logloss:0.21646\n[1000]\ttrain-logloss:0.19781\tvalid-logloss:0.21630\n[1100]\ttrain-logloss:0.19585\tvalid-logloss:0.21614\n[1200]\ttrain-logloss:0.19387\tvalid-logloss:0.21599\n[1300]\ttrain-logloss:0.19193\tvalid-logloss:0.21583\n[1400]\ttrain-logloss:0.19012\tvalid-logloss:0.21579\n[1500]\ttrain-logloss:0.18833\tvalid-logloss:0.21568\n[1600]\ttrain-logloss:0.18650\tvalid-logloss:0.21562\n[1700]\ttrain-logloss:0.18473\tvalid-logloss:0.21558\n[1800]\ttrain-logloss:0.18298\tvalid-logloss:0.21547\n[1900]\ttrain-logloss:0.18132\tvalid-logloss:0.21545\n[2000]\ttrain-logloss:0.17963\tvalid-logloss:0.21543\n[2100]\ttrain-logloss:0.17801\tvalid-logloss:0.21540\n[2200]\ttrain-logloss:0.17640\tvalid-logloss:0.21539\n[2300]\ttrain-logloss:0.17486\tvalid-logloss:0.21537\n[2400]\ttrain-logloss:0.17331\tvalid-logloss:0.21535\n[2479]\ttrain-logloss:0.17212\tvalid-logloss:0.21537\nKaggle Metric on valid set = 0.7946437200173261 \n\nKaggle Metric on all dataset = 0.8554735446511862 \n\n#########################\nOVERALL CV Kaggle Metric = 0.7915386392343893\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## CatBoost","metadata":{}},{"cell_type":"markdown","source":"CatBoost is based on the same method than XGBoost but could  be more efficient.\nWe apply the same code than before but training a catboost.","metadata":{}},{"cell_type":"code","source":"# GET CATEG VARIABLES\ncat_features = [\"B_30\", \"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\ncateg = []\n#print(train.columns)\nfor col in train.columns :\n    if col not in ['customer_ID', 'target'] :\n        VAR = '_'.join(col.split('_')[:2])\n        if VAR in cat_features :\n            categ.append(col)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T09:35:58.732948Z","iopub.execute_input":"2022-08-31T09:35:58.733311Z","iopub.status.idle":"2022-08-31T09:35:58.741415Z","shell.execute_reply.started":"2022-08-31T09:35:58.733261Z","shell.execute_reply":"2022-08-31T09:35:58.740424Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"oof = []\nskf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\nfor fold,(train_idx, valid_idx) in enumerate(skf.split(\n            train, train.target )):\n    print('#'*25)\n    print('### Fold',fold+1)\n    print('### Train size',len(train_idx),'Valid size',len(valid_idx))\n    print(f'### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...')\n    print('#'*25)\n    train_pool = Pool(train.loc[train_idx, FEATURES],\n                      train.loc[train_idx, 'target'],\n                      cat_features=categ\n                     )\n    valid_pool = Pool(train.loc[valid_idx, FEATURES],\n                      train.loc[valid_idx, 'target'],\n                      cat_features=categ\n                     )\n    model = CatBoostClassifier(iterations=9999,\n                               random_state=SEED,\n                               task_type=\"GPU\",\n                               loss_function = 'Logloss',\n                               learning_rate=0.05\n                               )\n    model.fit(train_pool, eval_set=valid_pool,\n              #od_type=\"Iter\",\n              early_stopping_rounds=100,\n              #od_wait=100,\n              verbose=100)\n    model.save_model(f'{ODIR}/CTB_all_features_v{VER}_fold{fold}.ctb')\n    valid_pred = model.predict_proba(valid_pool)[:,1]\n    val_acc = amex_metric_mod(train.loc[valid_idx, 'target'].values, valid_pred)\n    print('Kaggle Metric on valid set =',val_acc,'\\n')\n\n    df = train.loc[valid_idx, ['customer_ID','target'] ].copy()\n    df['oof_pred'] = valid_pred\n    oof.append( df )\n\n    del train_pool, valid_pool, df\n    _ = gc.collect()\n\n    all_pool = Pool(train[FEATURES],\n                    train['target'],\n                    cat_features=categ\n                     )\n    pred = model.predict_proba(all_pool)[:,1]\n    all_acc = amex_metric_mod(train['target'].values, pred)\n    print('Kaggle Metric on all dataset =',all_acc,'\\n')\n    result_all = result_all.append({'model' : \"CateBoost\",\n                                    'preprocessing' : \"huseyincot_all_feat\",\n                                    'name' : f'CTB_all_features_v{VER}_fold{fold}',\n                                    'y_valid_pred' : valid_pred,\n                                    'valid_acc' : val_acc,\n                                    'y_pred' : pred,\n                                    'acc' : all_acc\n                                   },\n                                   ignore_index=True\n                                  )\n    del all_pool, pred, valid_pred\n    _ = gc.collect()\n\nprint('#'*25)\noof = pd.concat(oof,axis=0,ignore_index=True).set_index('customer_ID')\nacc = amex_metric_mod(oof.target.values, oof.oof_pred.values)\nresult_sum = result_sum.append({'model' : \"CateBoost\",\n                                'preprocessing':\"huseyincot_all_feat\",\n                                'name' : \"CTB_huseyincot_all_feat\",\n                                'y_pred' : oof,\n                                'acc': acc\n                               },\n                               ignore_index=True\n                              )\nprint('OVERALL CV Kaggle Metric =',acc)\n\ndel oof, acc\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T09:35:58.743179Z","iopub.execute_input":"2022-08-31T09:35:58.743738Z","iopub.status.idle":"2022-08-31T10:09:59.799707Z","shell.execute_reply.started":"2022-08-31T09:35:58.743686Z","shell.execute_reply":"2022-08-31T10:09:59.797745Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"#########################\n### Fold 1\n### Train size 367130 Valid size 91783\n### Training with 100% fold data...\n#########################\n0:\tlearn: 0.6337220\ttest: 0.6336139\tbest: 0.6336139 (0)\ttotal: 120ms\tremaining: 20m 3s\n100:\tlearn: 0.2306908\ttest: 0.2325585\tbest: 0.2325585 (100)\ttotal: 11.2s\tremaining: 18m 16s\n200:\tlearn: 0.2234131\ttest: 0.2263068\tbest: 0.2263068 (200)\ttotal: 22s\tremaining: 17m 52s\n300:\tlearn: 0.2195866\ttest: 0.2236417\tbest: 0.2236417 (300)\ttotal: 33.2s\tremaining: 17m 49s\n400:\tlearn: 0.2169051\ttest: 0.2221936\tbest: 0.2221936 (400)\ttotal: 44s\tremaining: 17m 33s\n500:\tlearn: 0.2148451\ttest: 0.2213693\tbest: 0.2213693 (500)\ttotal: 54.7s\tremaining: 17m 16s\n600:\tlearn: 0.2130150\ttest: 0.2207341\tbest: 0.2207341 (600)\ttotal: 1m 6s\tremaining: 17m 14s\n700:\tlearn: 0.2114121\ttest: 0.2201840\tbest: 0.2201840 (700)\ttotal: 1m 16s\tremaining: 16m 58s\n800:\tlearn: 0.2098911\ttest: 0.2198174\tbest: 0.2198174 (800)\ttotal: 1m 27s\tremaining: 16m 45s\n900:\tlearn: 0.2085943\ttest: 0.2195417\tbest: 0.2195417 (900)\ttotal: 1m 38s\tremaining: 16m 36s\n1000:\tlearn: 0.2073066\ttest: 0.2193357\tbest: 0.2193357 (1000)\ttotal: 1m 49s\tremaining: 16m 22s\n1100:\tlearn: 0.2060625\ttest: 0.2191344\tbest: 0.2191344 (1100)\ttotal: 1m 59s\tremaining: 16m 9s\n1200:\tlearn: 0.2048036\ttest: 0.2189094\tbest: 0.2189094 (1200)\ttotal: 2m 11s\tremaining: 16m 1s\n1300:\tlearn: 0.2035677\ttest: 0.2187672\tbest: 0.2187672 (1300)\ttotal: 2m 21s\tremaining: 15m 48s\n1400:\tlearn: 0.2024271\ttest: 0.2185739\tbest: 0.2185739 (1395)\ttotal: 2m 32s\tremaining: 15m 36s\n1500:\tlearn: 0.2012754\ttest: 0.2184189\tbest: 0.2184189 (1500)\ttotal: 2m 43s\tremaining: 15m 27s\n1600:\tlearn: 0.2000849\ttest: 0.2182541\tbest: 0.2182541 (1600)\ttotal: 2m 54s\tremaining: 15m 15s\n1700:\tlearn: 0.1989141\ttest: 0.2181137\tbest: 0.2181137 (1700)\ttotal: 3m 5s\tremaining: 15m 6s\n1800:\tlearn: 0.1978023\ttest: 0.2180398\tbest: 0.2180398 (1800)\ttotal: 3m 16s\tremaining: 14m 55s\n1900:\tlearn: 0.1967071\ttest: 0.2179130\tbest: 0.2179130 (1900)\ttotal: 3m 27s\tremaining: 14m 43s\n2000:\tlearn: 0.1956625\ttest: 0.2178552\tbest: 0.2178552 (2000)\ttotal: 3m 38s\tremaining: 14m 34s\n2100:\tlearn: 0.1946520\ttest: 0.2177938\tbest: 0.2177837 (2094)\ttotal: 3m 49s\tremaining: 14m 22s\n2200:\tlearn: 0.1935619\ttest: 0.2176415\tbest: 0.2176390 (2191)\ttotal: 4m\tremaining: 14m 10s\n2300:\tlearn: 0.1925184\ttest: 0.2175262\tbest: 0.2175217 (2291)\ttotal: 4m 11s\tremaining: 14m 1s\n2400:\tlearn: 0.1914928\ttest: 0.2174966\tbest: 0.2174927 (2397)\ttotal: 4m 21s\tremaining: 13m 48s\n2500:\tlearn: 0.1904921\ttest: 0.2174132\tbest: 0.2174132 (2500)\ttotal: 4m 32s\tremaining: 13m 37s\n2600:\tlearn: 0.1894629\ttest: 0.2173681\tbest: 0.2173624 (2598)\ttotal: 4m 43s\tremaining: 13m 27s\n2700:\tlearn: 0.1884798\ttest: 0.2173001\tbest: 0.2173001 (2700)\ttotal: 4m 54s\tremaining: 13m 15s\n2800:\tlearn: 0.1875335\ttest: 0.2172541\tbest: 0.2172511 (2799)\ttotal: 5m 5s\tremaining: 13m 4s\n2900:\tlearn: 0.1866049\ttest: 0.2172497\tbest: 0.2172370 (2855)\ttotal: 5m 16s\tremaining: 12m 54s\n3000:\tlearn: 0.1856296\ttest: 0.2171712\tbest: 0.2171712 (3000)\ttotal: 5m 27s\tremaining: 12m 43s\n3100:\tlearn: 0.1846545\ttest: 0.2171191\tbest: 0.2171191 (3100)\ttotal: 5m 38s\tremaining: 12m 32s\n3200:\tlearn: 0.1837294\ttest: 0.2170091\tbest: 0.2170091 (3200)\ttotal: 5m 49s\tremaining: 12m 22s\n3300:\tlearn: 0.1828255\ttest: 0.2169530\tbest: 0.2169529 (3297)\ttotal: 6m\tremaining: 12m 10s\n3400:\tlearn: 0.1818718\ttest: 0.2168822\tbest: 0.2168812 (3399)\ttotal: 6m 10s\tremaining: 11m 59s\n3500:\tlearn: 0.1809508\ttest: 0.2168494\tbest: 0.2168494 (3500)\ttotal: 6m 22s\tremaining: 11m 49s\n3600:\tlearn: 0.1800526\ttest: 0.2168089\tbest: 0.2168089 (3600)\ttotal: 6m 33s\tremaining: 11m 38s\n3700:\tlearn: 0.1791764\ttest: 0.2167872\tbest: 0.2167814 (3696)\ttotal: 6m 43s\tremaining: 11m 26s\n3800:\tlearn: 0.1782674\ttest: 0.2167345\tbest: 0.2167286 (3794)\ttotal: 6m 55s\tremaining: 11m 16s\n3900:\tlearn: 0.1774131\ttest: 0.2166947\tbest: 0.2166917 (3891)\ttotal: 7m 5s\tremaining: 11m 5s\n4000:\tlearn: 0.1765268\ttest: 0.2166523\tbest: 0.2166497 (3999)\ttotal: 7m 16s\tremaining: 10m 54s\n4100:\tlearn: 0.1756783\ttest: 0.2165758\tbest: 0.2165758 (4100)\ttotal: 7m 28s\tremaining: 10m 44s\n4200:\tlearn: 0.1748316\ttest: 0.2165421\tbest: 0.2165365 (4194)\ttotal: 7m 38s\tremaining: 10m 33s\nbestTest = 0.2165365378\nbestIteration = 4194\nShrink model to first 4195 iterations.\nKaggle Metric on valid set = 0.7940031548283464 \n\nKaggle Metric on all dataset = 0.8599299277086581 \n\n#########################\n### Fold 2\n### Train size 367130 Valid size 91783\n### Training with 100% fold data...\n#########################\n0:\tlearn: 0.6329661\ttest: 0.6328071\tbest: 0.6328071 (0)\ttotal: 112ms\tremaining: 18m 41s\n100:\tlearn: 0.2313771\ttest: 0.2314318\tbest: 0.2314318 (100)\ttotal: 11.1s\tremaining: 18m 12s\n200:\tlearn: 0.2237405\ttest: 0.2250527\tbest: 0.2250527 (200)\ttotal: 22.1s\tremaining: 17m 59s\n300:\tlearn: 0.2200649\ttest: 0.2225631\tbest: 0.2225631 (300)\ttotal: 33.6s\tremaining: 18m 1s\n400:\tlearn: 0.2173477\ttest: 0.2210666\tbest: 0.2210666 (400)\ttotal: 44.4s\tremaining: 17m 42s\n500:\tlearn: 0.2151948\ttest: 0.2201611\tbest: 0.2201611 (500)\ttotal: 55.1s\tremaining: 17m 24s\n600:\tlearn: 0.2134346\ttest: 0.2196661\tbest: 0.2196661 (600)\ttotal: 1m 6s\tremaining: 17m 18s\n700:\tlearn: 0.2117775\ttest: 0.2192059\tbest: 0.2192059 (700)\ttotal: 1m 17s\tremaining: 17m 4s\n800:\tlearn: 0.2102196\ttest: 0.2189085\tbest: 0.2189084 (799)\ttotal: 1m 27s\tremaining: 16m 48s\n900:\tlearn: 0.2087447\ttest: 0.2185365\tbest: 0.2185365 (900)\ttotal: 1m 39s\tremaining: 16m 41s\n1000:\tlearn: 0.2073998\ttest: 0.2182763\tbest: 0.2182763 (1000)\ttotal: 1m 49s\tremaining: 16m 27s\n1100:\tlearn: 0.2061498\ttest: 0.2180814\tbest: 0.2180814 (1100)\ttotal: 2m\tremaining: 16m 14s\n1200:\tlearn: 0.2048960\ttest: 0.2178876\tbest: 0.2178801 (1195)\ttotal: 2m 11s\tremaining: 16m 5s\n1300:\tlearn: 0.2036619\ttest: 0.2177006\tbest: 0.2176998 (1296)\ttotal: 2m 22s\tremaining: 15m 52s\n1400:\tlearn: 0.2024910\ttest: 0.2175800\tbest: 0.2175800 (1400)\ttotal: 2m 33s\tremaining: 15m 40s\n1500:\tlearn: 0.2012601\ttest: 0.2174092\tbest: 0.2174092 (1500)\ttotal: 2m 44s\tremaining: 15m 32s\n1600:\tlearn: 0.2001707\ttest: 0.2172920\tbest: 0.2172894 (1597)\ttotal: 2m 55s\tremaining: 15m 20s\n1700:\tlearn: 0.1990211\ttest: 0.2171652\tbest: 0.2171652 (1700)\ttotal: 3m 6s\tremaining: 15m 8s\n1800:\tlearn: 0.1979533\ttest: 0.2170578\tbest: 0.2170573 (1798)\ttotal: 3m 17s\tremaining: 14m 57s\n1900:\tlearn: 0.1969252\ttest: 0.2169817\tbest: 0.2169817 (1900)\ttotal: 3m 27s\tremaining: 14m 45s\n2000:\tlearn: 0.1958061\ttest: 0.2168929\tbest: 0.2168856 (1989)\ttotal: 3m 38s\tremaining: 14m 33s\n2100:\tlearn: 0.1947411\ttest: 0.2168152\tbest: 0.2168118 (2094)\ttotal: 3m 49s\tremaining: 14m 24s\n2200:\tlearn: 0.1936971\ttest: 0.2167366\tbest: 0.2167330 (2196)\ttotal: 4m\tremaining: 14m 12s\n2300:\tlearn: 0.1927137\ttest: 0.2166823\tbest: 0.2166748 (2292)\ttotal: 4m 11s\tremaining: 14m\n2400:\tlearn: 0.1916967\ttest: 0.2166503\tbest: 0.2166474 (2382)\ttotal: 4m 22s\tremaining: 13m 50s\n2500:\tlearn: 0.1906919\ttest: 0.2165961\tbest: 0.2165926 (2491)\ttotal: 4m 32s\tremaining: 13m 38s\n2600:\tlearn: 0.1897384\ttest: 0.2165710\tbest: 0.2165613 (2575)\ttotal: 4m 44s\tremaining: 13m 27s\nbestTest = 0.2165612649\nbestIteration = 2575\nShrink model to first 2576 iterations.\nKaggle Metric on valid set = 0.7945407675830432 \n\nKaggle Metric on all dataset = 0.836942414204036 \n\n#########################\n### Fold 3\n### Train size 367130 Valid size 91783\n### Training with 100% fold data...\n#########################\n0:\tlearn: 0.6302516\ttest: 0.6305213\tbest: 0.6305213 (0)\ttotal: 114ms\tremaining: 18m 56s\n100:\tlearn: 0.2308045\ttest: 0.2337684\tbest: 0.2337684 (100)\ttotal: 11.2s\tremaining: 18m 16s\n200:\tlearn: 0.2232211\ttest: 0.2275582\tbest: 0.2275582 (200)\ttotal: 22.3s\tremaining: 18m 7s\n300:\tlearn: 0.2193645\ttest: 0.2249935\tbest: 0.2249935 (300)\ttotal: 33.1s\tremaining: 17m 47s\n400:\tlearn: 0.2166021\ttest: 0.2236147\tbest: 0.2236147 (400)\ttotal: 43.9s\tremaining: 17m 31s\n500:\tlearn: 0.2145371\ttest: 0.2228129\tbest: 0.2228128 (499)\ttotal: 55.3s\tremaining: 17m 27s\n600:\tlearn: 0.2126696\ttest: 0.2221975\tbest: 0.2221975 (600)\ttotal: 1m 6s\tremaining: 17m 12s\n700:\tlearn: 0.2110607\ttest: 0.2217474\tbest: 0.2217474 (700)\ttotal: 1m 16s\tremaining: 16m 56s\n800:\tlearn: 0.2096415\ttest: 0.2214403\tbest: 0.2214403 (800)\ttotal: 1m 27s\tremaining: 16m 50s\n900:\tlearn: 0.2082782\ttest: 0.2211579\tbest: 0.2211579 (900)\ttotal: 1m 38s\tremaining: 16m 35s\n1000:\tlearn: 0.2069706\ttest: 0.2209718\tbest: 0.2209718 (1000)\ttotal: 1m 49s\tremaining: 16m 21s\n1100:\tlearn: 0.2056803\ttest: 0.2207715\tbest: 0.2207715 (1100)\ttotal: 2m\tremaining: 16m 14s\n1200:\tlearn: 0.2044534\ttest: 0.2206009\tbest: 0.2206009 (1200)\ttotal: 2m 11s\tremaining: 16m\n1300:\tlearn: 0.2032109\ttest: 0.2204870\tbest: 0.2204818 (1290)\ttotal: 2m 21s\tremaining: 15m 48s\n1400:\tlearn: 0.2020103\ttest: 0.2203847\tbest: 0.2203843 (1392)\ttotal: 2m 32s\tremaining: 15m 38s\n1500:\tlearn: 0.2008833\ttest: 0.2202610\tbest: 0.2202603 (1499)\ttotal: 2m 43s\tremaining: 15m 25s\n1600:\tlearn: 0.1997296\ttest: 0.2201646\tbest: 0.2201624 (1598)\ttotal: 2m 54s\tremaining: 15m 14s\n1700:\tlearn: 0.1986921\ttest: 0.2200704\tbest: 0.2200638 (1696)\ttotal: 3m 5s\tremaining: 15m 5s\n1800:\tlearn: 0.1976089\ttest: 0.2200174\tbest: 0.2200174 (1800)\ttotal: 3m 16s\tremaining: 14m 53s\n1900:\tlearn: 0.1965361\ttest: 0.2199151\tbest: 0.2199141 (1887)\ttotal: 3m 26s\tremaining: 14m 41s\n2000:\tlearn: 0.1954963\ttest: 0.2198238\tbest: 0.2198238 (2000)\ttotal: 3m 38s\tremaining: 14m 32s\n2100:\tlearn: 0.1944143\ttest: 0.2197480\tbest: 0.2197480 (2100)\ttotal: 3m 49s\tremaining: 14m 21s\n2200:\tlearn: 0.1933562\ttest: 0.2197047\tbest: 0.2197045 (2184)\ttotal: 3m 59s\tremaining: 14m 9s\n2300:\tlearn: 0.1923257\ttest: 0.2196310\tbest: 0.2196310 (2300)\ttotal: 4m 11s\tremaining: 14m\n2400:\tlearn: 0.1913131\ttest: 0.2195604\tbest: 0.2195575 (2396)\ttotal: 4m 21s\tremaining: 13m 48s\n2500:\tlearn: 0.1902893\ttest: 0.2195245\tbest: 0.2195245 (2500)\ttotal: 4m 32s\tremaining: 13m 37s\n2600:\tlearn: 0.1892870\ttest: 0.2194930\tbest: 0.2194769 (2572)\ttotal: 4m 43s\tremaining: 13m 27s\n2700:\tlearn: 0.1882632\ttest: 0.2194186\tbest: 0.2194186 (2700)\ttotal: 4m 54s\tremaining: 13m 16s\n2800:\tlearn: 0.1872695\ttest: 0.2193600\tbest: 0.2193566 (2799)\ttotal: 5m 5s\tremaining: 13m 5s\n2900:\tlearn: 0.1863118\ttest: 0.2193314\tbest: 0.2193314 (2900)\ttotal: 5m 16s\tremaining: 12m 55s\n3000:\tlearn: 0.1853647\ttest: 0.2193001\tbest: 0.2193001 (3000)\ttotal: 5m 27s\tremaining: 12m 43s\n3100:\tlearn: 0.1844646\ttest: 0.2193207\tbest: 0.2192962 (3001)\ttotal: 5m 38s\tremaining: 12m 33s\nbestTest = 0.2192961889\nbestIteration = 3001\nShrink model to first 3002 iterations.\nKaggle Metric on valid set = 0.7913994511439725 \n\nKaggle Metric on all dataset = 0.8430667497295776 \n\n#########################\n### Fold 4\n### Train size 367131 Valid size 91782\n### Training with 100% fold data...\n#########################\n0:\tlearn: 0.6322399\ttest: 0.6324573\tbest: 0.6324573 (0)\ttotal: 112ms\tremaining: 18m 42s\n100:\tlearn: 0.2308302\ttest: 0.2341012\tbest: 0.2341012 (100)\ttotal: 11s\tremaining: 17m 56s\n200:\tlearn: 0.2231037\ttest: 0.2278401\tbest: 0.2278401 (200)\ttotal: 21.8s\tremaining: 17m 40s\n300:\tlearn: 0.2192783\ttest: 0.2254109\tbest: 0.2254109 (300)\ttotal: 33.1s\tremaining: 17m 47s\n400:\tlearn: 0.2166420\ttest: 0.2241018\tbest: 0.2241018 (400)\ttotal: 43.9s\tremaining: 17m 30s\n500:\tlearn: 0.2145380\ttest: 0.2232028\tbest: 0.2232028 (500)\ttotal: 54.6s\tremaining: 17m 15s\n600:\tlearn: 0.2127360\ttest: 0.2226682\tbest: 0.2226682 (600)\ttotal: 1m 6s\tremaining: 17m 13s\n700:\tlearn: 0.2111182\ttest: 0.2221985\tbest: 0.2221985 (700)\ttotal: 1m 16s\tremaining: 16m 59s\n800:\tlearn: 0.2095837\ttest: 0.2218298\tbest: 0.2218298 (800)\ttotal: 1m 27s\tremaining: 16m 43s\n900:\tlearn: 0.2082038\ttest: 0.2215517\tbest: 0.2215517 (900)\ttotal: 1m 38s\tremaining: 16m 34s\n1000:\tlearn: 0.2068752\ttest: 0.2212567\tbest: 0.2212566 (999)\ttotal: 1m 49s\tremaining: 16m 21s\n1100:\tlearn: 0.2055580\ttest: 0.2210474\tbest: 0.2210436 (1096)\ttotal: 2m\tremaining: 16m 10s\n1200:\tlearn: 0.2042838\ttest: 0.2208699\tbest: 0.2208699 (1200)\ttotal: 2m 11s\tremaining: 16m 3s\n1300:\tlearn: 0.2030383\ttest: 0.2207481\tbest: 0.2207481 (1300)\ttotal: 2m 22s\tremaining: 15m 50s\n1400:\tlearn: 0.2018815\ttest: 0.2206487\tbest: 0.2206487 (1400)\ttotal: 2m 33s\tremaining: 15m 41s\n1500:\tlearn: 0.2006853\ttest: 0.2205507\tbest: 0.2205507 (1500)\ttotal: 2m 44s\tremaining: 15m 31s\n1600:\tlearn: 0.1995592\ttest: 0.2204300\tbest: 0.2204292 (1593)\ttotal: 2m 55s\tremaining: 15m 18s\n1700:\tlearn: 0.1984572\ttest: 0.2203305\tbest: 0.2203298 (1698)\ttotal: 3m 6s\tremaining: 15m 10s\n1800:\tlearn: 0.1973499\ttest: 0.2202354\tbest: 0.2202346 (1795)\ttotal: 3m 17s\tremaining: 14m 58s\n1900:\tlearn: 0.1962593\ttest: 0.2201864\tbest: 0.2201814 (1891)\ttotal: 3m 28s\tremaining: 14m 47s\n2000:\tlearn: 0.1951958\ttest: 0.2201094\tbest: 0.2201094 (2000)\ttotal: 3m 39s\tremaining: 14m 37s\n2100:\tlearn: 0.1941903\ttest: 0.2200114\tbest: 0.2200061 (2092)\ttotal: 3m 50s\tremaining: 14m 25s\n2200:\tlearn: 0.1931131\ttest: 0.2199715\tbest: 0.2199601 (2194)\ttotal: 4m\tremaining: 14m 13s\n2300:\tlearn: 0.1920658\ttest: 0.2199021\tbest: 0.2198987 (2268)\ttotal: 4m 12s\tremaining: 14m 4s\n2400:\tlearn: 0.1909901\ttest: 0.2198585\tbest: 0.2198565 (2399)\ttotal: 4m 23s\tremaining: 13m 52s\n2500:\tlearn: 0.1899801\ttest: 0.2197851\tbest: 0.2197837 (2499)\ttotal: 4m 33s\tremaining: 13m 40s\n2600:\tlearn: 0.1889890\ttest: 0.2197472\tbest: 0.2197466 (2599)\ttotal: 4m 45s\tremaining: 13m 31s\n2700:\tlearn: 0.1879938\ttest: 0.2196858\tbest: 0.2196802 (2689)\ttotal: 4m 55s\tremaining: 13m 19s\n2800:\tlearn: 0.1870111\ttest: 0.2196443\tbest: 0.2196437 (2799)\ttotal: 5m 6s\tremaining: 13m 7s\n2900:\tlearn: 0.1860408\ttest: 0.2196516\tbest: 0.2196329 (2865)\ttotal: 5m 17s\tremaining: 12m 57s\nbestTest = 0.2196328665\nbestIteration = 2865\nShrink model to first 2866 iterations.\nKaggle Metric on valid set = 0.7878246886625178 \n\nKaggle Metric on all dataset = 0.8411339639961068 \n\n#########################\n### Fold 5\n### Train size 367131 Valid size 91782\n### Training with 100% fold data...\n#########################\n0:\tlearn: 0.6325262\ttest: 0.6324742\tbest: 0.6324742 (0)\ttotal: 113ms\tremaining: 18m 50s\n100:\tlearn: 0.2315166\ttest: 0.2313154\tbest: 0.2313154 (100)\ttotal: 11.1s\tremaining: 18m 9s\n200:\tlearn: 0.2240446\ttest: 0.2248328\tbest: 0.2248328 (200)\ttotal: 22.4s\tremaining: 18m 10s\n300:\tlearn: 0.2201482\ttest: 0.2220167\tbest: 0.2220167 (300)\ttotal: 33.3s\tremaining: 17m 52s\n400:\tlearn: 0.2175643\ttest: 0.2206466\tbest: 0.2206466 (400)\ttotal: 43.9s\tremaining: 17m 31s\n500:\tlearn: 0.2154146\ttest: 0.2196474\tbest: 0.2196474 (500)\ttotal: 55.3s\tremaining: 17m 27s\n600:\tlearn: 0.2136866\ttest: 0.2190598\tbest: 0.2190598 (600)\ttotal: 1m 5s\tremaining: 17m 11s\n700:\tlearn: 0.2120561\ttest: 0.2185939\tbest: 0.2185939 (700)\ttotal: 1m 16s\tremaining: 16m 58s\n800:\tlearn: 0.2105643\ttest: 0.2182251\tbest: 0.2182227 (798)\ttotal: 1m 27s\tremaining: 16m 50s\n900:\tlearn: 0.2091980\ttest: 0.2179852\tbest: 0.2179852 (900)\ttotal: 1m 38s\tremaining: 16m 36s\n1000:\tlearn: 0.2078600\ttest: 0.2176824\tbest: 0.2176824 (1000)\ttotal: 1m 49s\tremaining: 16m 21s\n1100:\tlearn: 0.2065616\ttest: 0.2174196\tbest: 0.2174196 (1100)\ttotal: 2m\tremaining: 16m 15s\n1200:\tlearn: 0.2053186\ttest: 0.2172183\tbest: 0.2172183 (1200)\ttotal: 2m 11s\tremaining: 16m 3s\n1300:\tlearn: 0.2041318\ttest: 0.2169926\tbest: 0.2169921 (1298)\ttotal: 2m 22s\tremaining: 15m 54s\n1400:\tlearn: 0.2029521\ttest: 0.2168304\tbest: 0.2168304 (1400)\ttotal: 2m 33s\tremaining: 15m 42s\n1500:\tlearn: 0.2017696\ttest: 0.2166670\tbest: 0.2166646 (1497)\ttotal: 2m 44s\tremaining: 15m 30s\n1600:\tlearn: 0.2005903\ttest: 0.2164899\tbest: 0.2164894 (1599)\ttotal: 2m 55s\tremaining: 15m 21s\n1700:\tlearn: 0.1994466\ttest: 0.2163943\tbest: 0.2163943 (1700)\ttotal: 3m 6s\tremaining: 15m 9s\n1800:\tlearn: 0.1983711\ttest: 0.2163122\tbest: 0.2163122 (1800)\ttotal: 3m 17s\tremaining: 14m 58s\n1900:\tlearn: 0.1972971\ttest: 0.2162184\tbest: 0.2162184 (1900)\ttotal: 3m 28s\tremaining: 14m 47s\n2000:\tlearn: 0.1962457\ttest: 0.2161330\tbest: 0.2161320 (1997)\ttotal: 3m 39s\tremaining: 14m 36s\n2100:\tlearn: 0.1951930\ttest: 0.2160446\tbest: 0.2160446 (2100)\ttotal: 3m 49s\tremaining: 14m 23s\n2200:\tlearn: 0.1941537\ttest: 0.2159695\tbest: 0.2159655 (2198)\ttotal: 4m 1s\tremaining: 14m 15s\n2300:\tlearn: 0.1931363\ttest: 0.2158865\tbest: 0.2158822 (2293)\ttotal: 4m 12s\tremaining: 14m 3s\n2400:\tlearn: 0.1921241\ttest: 0.2158626\tbest: 0.2158504 (2330)\ttotal: 4m 22s\tremaining: 13m 52s\n2500:\tlearn: 0.1910453\ttest: 0.2157809\tbest: 0.2157809 (2500)\ttotal: 4m 34s\tremaining: 13m 42s\n2600:\tlearn: 0.1900811\ttest: 0.2157229\tbest: 0.2157187 (2580)\ttotal: 4m 45s\tremaining: 13m 30s\n2700:\tlearn: 0.1890678\ttest: 0.2156705\tbest: 0.2156610 (2697)\ttotal: 4m 55s\tremaining: 13m 19s\n2800:\tlearn: 0.1880833\ttest: 0.2156247\tbest: 0.2156118 (2791)\ttotal: 5m 7s\tremaining: 13m 9s\n2900:\tlearn: 0.1871178\ttest: 0.2155881\tbest: 0.2155865 (2898)\ttotal: 5m 18s\tremaining: 12m 58s\n3000:\tlearn: 0.1861586\ttest: 0.2155714\tbest: 0.2155696 (2994)\ttotal: 5m 28s\tremaining: 12m 46s\n3100:\tlearn: 0.1851969\ttest: 0.2155811\tbest: 0.2155580 (3006)\ttotal: 5m 40s\tremaining: 12m 36s\nbestTest = 0.2155579721\nbestIteration = 3006\nShrink model to first 3007 iterations.\nKaggle Metric on valid set = 0.7958369927877813 \n\nKaggle Metric on all dataset = 0.8430603077357024 \n\n#########################\nOVERALL CV Kaggle Metric = 0.7927899116150396\n","output_type":"stream"}]},{"cell_type":"code","source":"del train\n_=gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T10:09:59.801085Z","iopub.execute_input":"2022-08-31T10:09:59.802533Z","iopub.status.idle":"2022-08-31T10:09:59.935768Z","shell.execute_reply.started":"2022-08-31T10:09:59.802495Z","shell.execute_reply":"2022-08-31T10:09:59.934663Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Removing Columns with a majority of NaN","metadata":{}},{"cell_type":"markdown","source":"The EDA shows us that some features contain huge amount of NaN values.\nThese features are removed.","metadata":{}},{"cell_type":"markdown","source":"## Load Dataset","metadata":{}},{"cell_type":"code","source":"train = read_file(path = TRAIN_PATH)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T10:09:59.937533Z","iopub.execute_input":"2022-08-31T10:09:59.937943Z","iopub.status.idle":"2022-08-31T10:10:13.909887Z","shell.execute_reply.started":"2022-08-31T10:09:59.937898Z","shell.execute_reply":"2022-08-31T10:10:13.908856Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"shape of data: (5531451, 190)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Select features","metadata":{}},{"cell_type":"markdown","source":"Features are deleted if more than 20% of values are NaN.","metadata":{}},{"cell_type":"code","source":"counter = train.isnull().sum(axis=0).sort_values(ascending=False)/len(train)*100\nrm_nan = counter[counter>20].index\nrm_nan = list(rm_nan.to_array())\nprint(f\"{len(rm_nan)}/{len(train.columns)}\")","metadata":{"execution":{"iopub.status.busy":"2022-08-31T10:10:13.91425Z","iopub.execute_input":"2022-08-31T10:10:13.916557Z","iopub.status.idle":"2022-08-31T10:10:14.247218Z","shell.execute_reply.started":"2022-08-31T10:10:13.916519Z","shell.execute_reply":"2022-08-31T10:10:14.246212Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"21/190\n","output_type":"stream"}]},{"cell_type":"code","source":"FEATURES_2 = [col for col in train.columns if col not in rm_nan]","metadata":{"execution":{"iopub.status.busy":"2022-08-31T10:10:14.248593Z","iopub.execute_input":"2022-08-31T10:10:14.251135Z","iopub.status.idle":"2022-08-31T10:10:14.257196Z","shell.execute_reply.started":"2022-08-31T10:10:14.251107Z","shell.execute_reply":"2022-08-31T10:10:14.255666Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train = train[FEATURES_2]","metadata":{"execution":{"iopub.status.busy":"2022-08-31T10:10:14.258961Z","iopub.execute_input":"2022-08-31T10:10:14.259384Z","iopub.status.idle":"2022-08-31T10:10:14.286311Z","shell.execute_reply.started":"2022-08-31T10:10:14.25935Z","shell.execute_reply":"2022-08-31T10:10:14.285034Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Processing","metadata":{}},{"cell_type":"markdown","source":"The same processing is applied","metadata":{}},{"cell_type":"code","source":"train = process_and_feature_engineer(train)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T10:10:14.287607Z","iopub.execute_input":"2022-08-31T10:10:14.287997Z","iopub.status.idle":"2022-08-31T10:10:16.163797Z","shell.execute_reply.started":"2022-08-31T10:10:14.287962Z","shell.execute_reply":"2022-08-31T10:10:16.162652Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"shape after engineering (458913, 813)\n","output_type":"stream"}]},{"cell_type":"code","source":"# ADD TARGETS\ntargets = cudf.read_csv('../input/amex-default-prediction/train_labels.csv')\ntargets['customer_ID'] = targets['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\ntargets = targets.set_index('customer_ID')\ntrain = train.merge(targets, left_index=True, right_index=True, how='left')\ntrain.target = train.target.astype('int8')\ndel targets\n\n# NEEDED TO MAKE CV DETERMINISTIC (cudf merge above randomly shuffles rows)\ntrain = train.sort_index().reset_index()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-31T10:10:16.166465Z","iopub.execute_input":"2022-08-31T10:10:16.167125Z","iopub.status.idle":"2022-08-31T10:10:16.955287Z","shell.execute_reply.started":"2022-08-31T10:10:16.167095Z","shell.execute_reply":"2022-08-31T10:10:16.954302Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"FEATURES_2 = train.columns[1:-1]","metadata":{"execution":{"iopub.status.busy":"2022-08-31T10:10:16.958585Z","iopub.execute_input":"2022-08-31T10:10:16.958982Z","iopub.status.idle":"2022-08-31T10:10:16.96419Z","shell.execute_reply.started":"2022-08-31T10:10:16.958947Z","shell.execute_reply":"2022-08-31T10:10:16.963228Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"with open(ODIR+'/all_features_2.pkl', 'wb') as ofile :\n    pickle.dump(FEATURES_2, ofile)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T10:10:16.96554Z","iopub.execute_input":"2022-08-31T10:10:16.966587Z","iopub.status.idle":"2022-08-31T10:10:16.977383Z","shell.execute_reply.started":"2022-08-31T10:10:16.96655Z","shell.execute_reply":"2022-08-31T10:10:16.976387Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"## XGBoost","metadata":{}},{"cell_type":"code","source":"train = train.to_pandas() # free GPU memory\nTRAIN_SUBSAMPLE = 1.0\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T10:10:16.978583Z","iopub.execute_input":"2022-08-31T10:10:16.979018Z","iopub.status.idle":"2022-08-31T10:10:19.655793Z","shell.execute_reply.started":"2022-08-31T10:10:16.978983Z","shell.execute_reply":"2022-08-31T10:10:19.654681Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"print('XGB Version',xgb.__version__)\n\n# XGB MODEL PARAMETERS\nxgb_parms = {\n    'max_depth':4,\n    'learning_rate':0.05,\n    'subsample':0.8,\n    'colsample_bytree':0.6,\n    'eval_metric':'logloss',\n    'objective':'binary:logistic',\n    'tree_method':'gpu_hist',\n    'predictor':'gpu_predictor',\n    'random_state':SEED\n}","metadata":{"execution":{"iopub.status.busy":"2022-08-31T10:10:19.657235Z","iopub.execute_input":"2022-08-31T10:10:19.657686Z","iopub.status.idle":"2022-08-31T10:10:19.664499Z","shell.execute_reply.started":"2022-08-31T10:10:19.657651Z","shell.execute_reply":"2022-08-31T10:10:19.663448Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"XGB Version 1.6.1\n","output_type":"stream"}]},{"cell_type":"code","source":"oof = []\nskf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\nfor fold,(train_idx, valid_idx) in enumerate(skf.split(\n            train, train.target )):\n    print('#'*25)\n    print('### Fold',fold+1)\n    print('### Train size',len(train_idx),'Valid size',len(valid_idx))\n    print(f'### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...')\n    print('#'*25)\n    dtrain = xgb.DMatrix(data=train.loc[train_idx, FEATURES_2], \\\n                        label=train.loc[train_idx, 'target'])\n    dvalid = xgb.DMatrix(data=train.loc[valid_idx, FEATURES_2], \\\n                        label=train.loc[valid_idx, 'target'])\n    model = xgb.train(xgb_parms,\n                      dtrain=dtrain,\n                      evals=[(dtrain,'train'),(dvalid,'valid')],\n                      num_boost_round=9999,\n                      #num_boost_round=99,\n                      early_stopping_rounds=100,\n                      verbose_eval=100)\n    model.save_model(f'{ODIR}/XGB_nonan_features_v{VER}_fold{fold}.xgb')\n    valid_pred = model.predict(dvalid)\n    val_acc = amex_metric_mod(train.loc[valid_idx, 'target'].values, valid_pred)\n    print('Kaggle Metric on valid set =',val_acc,'\\n')\n\n    df = train.loc[valid_idx, ['customer_ID','target'] ].copy()\n    df['oof_pred'] = valid_pred\n    oof.append( df )\n\n    del dtrain, dvalid, df\n    _ = gc.collect()\n\n    dall = xgb.DMatrix(data=train[FEATURES_2], label=train['target'])\n    pred = model.predict(dall)\n    all_acc = amex_metric_mod(train['target'].values, pred)\n    print('Kaggle Metric on all dataset =',all_acc,'\\n')\n    #result_all = result_all.append({'model' : \"XGBoost\",\n    #                                'preprocessing' : \"huseyincot_nonan_feat\",\n    #                                'name' : f'XGB_nonan_features_v{VER}_fold{fold}',\n    #                                'y_valid_pred' : valid_pred,\n    #                                'valid_acc' : val_acc,\n    #                                'y_pred' : pred,\n    #                                'acc' : all_acc\n    #                               },\n    #                               ignore_index=True\n    #                              )\n    del dall, pred, valid_pred\n    _ = gc.collect()\nprint('#'*25)\noof = pd.concat(oof,axis=0,ignore_index=True).set_index('customer_ID')\nacc = amex_metric_mod(oof.target.values, oof.oof_pred.values)\n#result_sum = result_sum.append({'model' : \"XGBoost\",\n#                                'preprocessing':\"huseyincot_nonan_feat\",\n#                                'name' : \"XGBoost_huseyincot_nonan_feat\",\n#                                'y_pred' : oof,\n#                                'acc': acc\n#                              },\n#                               ignore_index=True\n#                              )\nprint('OVERALL CV Kaggle Metric =',acc)\n\ndel oof, acc\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T10:10:19.666461Z","iopub.execute_input":"2022-08-31T10:10:19.666832Z","iopub.status.idle":"2022-08-31T10:18:24.621457Z","shell.execute_reply.started":"2022-08-31T10:10:19.666799Z","shell.execute_reply":"2022-08-31T10:18:24.619545Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"#########################\n### Fold 1\n### Train size 367130 Valid size 91783\n### Training with 100% fold data...\n#########################\n[0]\ttrain-logloss:0.66204\tvalid-logloss:0.66210\n[100]\ttrain-logloss:0.23852\tvalid-logloss:0.24137\n[200]\ttrain-logloss:0.22436\tvalid-logloss:0.22964\n[300]\ttrain-logloss:0.21834\tvalid-logloss:0.22552\n[400]\ttrain-logloss:0.21435\tvalid-logloss:0.22349\n[500]\ttrain-logloss:0.21111\tvalid-logloss:0.22226\n[600]\ttrain-logloss:0.20834\tvalid-logloss:0.22136\n[700]\ttrain-logloss:0.20592\tvalid-logloss:0.22086\n[800]\ttrain-logloss:0.20364\tvalid-logloss:0.22044\n[900]\ttrain-logloss:0.20149\tvalid-logloss:0.22008\n[1000]\ttrain-logloss:0.19943\tvalid-logloss:0.21982\n[1100]\ttrain-logloss:0.19746\tvalid-logloss:0.21967\n[1200]\ttrain-logloss:0.19554\tvalid-logloss:0.21951\n[1300]\ttrain-logloss:0.19373\tvalid-logloss:0.21935\n[1400]\ttrain-logloss:0.19192\tvalid-logloss:0.21926\n[1500]\ttrain-logloss:0.19015\tvalid-logloss:0.21912\n[1600]\ttrain-logloss:0.18838\tvalid-logloss:0.21902\n[1700]\ttrain-logloss:0.18667\tvalid-logloss:0.21897\n[1800]\ttrain-logloss:0.18492\tvalid-logloss:0.21891\n[1900]\ttrain-logloss:0.18322\tvalid-logloss:0.21889\n[2000]\ttrain-logloss:0.18160\tvalid-logloss:0.21888\n[2020]\ttrain-logloss:0.18129\tvalid-logloss:0.21890\nKaggle Metric on valid set = 0.7892849812241065 \n\nKaggle Metric on all dataset = 0.8422349787781016 \n\n#########################\n### Fold 2\n### Train size 367130 Valid size 91783\n### Training with 100% fold data...\n#########################\n[0]\ttrain-logloss:0.66203\tvalid-logloss:0.66201\n[100]\ttrain-logloss:0.23907\tvalid-logloss:0.23953\n[200]\ttrain-logloss:0.22474\tvalid-logloss:0.22726\n[300]\ttrain-logloss:0.21871\tvalid-logloss:0.22344\n[400]\ttrain-logloss:0.21473\tvalid-logloss:0.22152\n[500]\ttrain-logloss:0.21150\tvalid-logloss:0.22038\n[600]\ttrain-logloss:0.20883\tvalid-logloss:0.21965\n[700]\ttrain-logloss:0.20643\tvalid-logloss:0.21921\n[800]\ttrain-logloss:0.20420\tvalid-logloss:0.21885\n[900]\ttrain-logloss:0.20202\tvalid-logloss:0.21859\n[1000]\ttrain-logloss:0.19993\tvalid-logloss:0.21842\n[1100]\ttrain-logloss:0.19797\tvalid-logloss:0.21827\n[1200]\ttrain-logloss:0.19608\tvalid-logloss:0.21823\n[1300]\ttrain-logloss:0.19420\tvalid-logloss:0.21812\n[1400]\ttrain-logloss:0.19244\tvalid-logloss:0.21803\n[1500]\ttrain-logloss:0.19066\tvalid-logloss:0.21806\n[1541]\ttrain-logloss:0.18997\tvalid-logloss:0.21808\nKaggle Metric on valid set = 0.7901657496753817 \n\nKaggle Metric on all dataset = 0.8306454779611921 \n\n#########################\n### Fold 3\n### Train size 367130 Valid size 91783\n### Training with 100% fold data...\n#########################\n[0]\ttrain-logloss:0.66202\tvalid-logloss:0.66213\n[100]\ttrain-logloss:0.23816\tvalid-logloss:0.24237\n[200]\ttrain-logloss:0.22397\tvalid-logloss:0.23058\n[300]\ttrain-logloss:0.21798\tvalid-logloss:0.22682\n[400]\ttrain-logloss:0.21397\tvalid-logloss:0.22487\n[500]\ttrain-logloss:0.21075\tvalid-logloss:0.22372\n[600]\ttrain-logloss:0.20803\tvalid-logloss:0.22302\n[700]\ttrain-logloss:0.20552\tvalid-logloss:0.22248\n[800]\ttrain-logloss:0.20325\tvalid-logloss:0.22224\n[900]\ttrain-logloss:0.20099\tvalid-logloss:0.22205\n[1000]\ttrain-logloss:0.19896\tvalid-logloss:0.22185\n[1100]\ttrain-logloss:0.19693\tvalid-logloss:0.22164\n[1200]\ttrain-logloss:0.19505\tvalid-logloss:0.22152\n[1300]\ttrain-logloss:0.19322\tvalid-logloss:0.22145\n[1400]\ttrain-logloss:0.19145\tvalid-logloss:0.22143\n[1500]\ttrain-logloss:0.18970\tvalid-logloss:0.22143\n[1553]\ttrain-logloss:0.18877\tvalid-logloss:0.22142\nKaggle Metric on valid set = 0.7871228171046667 \n\nKaggle Metric on all dataset = 0.830034731547658 \n\n#########################\n### Fold 4\n### Train size 367131 Valid size 91782\n### Training with 100% fold data...\n#########################\n[0]\ttrain-logloss:0.66203\tvalid-logloss:0.66217\n[100]\ttrain-logloss:0.23821\tvalid-logloss:0.24283\n[200]\ttrain-logloss:0.22394\tvalid-logloss:0.23071\n[300]\ttrain-logloss:0.21798\tvalid-logloss:0.22703\n[400]\ttrain-logloss:0.21396\tvalid-logloss:0.22508\n[500]\ttrain-logloss:0.21083\tvalid-logloss:0.22399\n[600]\ttrain-logloss:0.20808\tvalid-logloss:0.22324\n[700]\ttrain-logloss:0.20563\tvalid-logloss:0.22273\n[800]\ttrain-logloss:0.20328\tvalid-logloss:0.22231\n[900]\ttrain-logloss:0.20117\tvalid-logloss:0.22200\n[1000]\ttrain-logloss:0.19909\tvalid-logloss:0.22186\n[1100]\ttrain-logloss:0.19711\tvalid-logloss:0.22170\n[1200]\ttrain-logloss:0.19516\tvalid-logloss:0.22162\n[1300]\ttrain-logloss:0.19326\tvalid-logloss:0.22149\n[1400]\ttrain-logloss:0.19143\tvalid-logloss:0.22142\n[1500]\ttrain-logloss:0.18964\tvalid-logloss:0.22141\n[1547]\ttrain-logloss:0.18881\tvalid-logloss:0.22139\nKaggle Metric on valid set = 0.7857135345723452 \n\nKaggle Metric on all dataset = 0.8308968404605919 \n\n#########################\n### Fold 5\n### Train size 367131 Valid size 91782\n### Training with 100% fold data...\n#########################\n[0]\ttrain-logloss:0.66207\tvalid-logloss:0.66198\n[100]\ttrain-logloss:0.23918\tvalid-logloss:0.23960\n[200]\ttrain-logloss:0.22489\tvalid-logloss:0.22748\n[300]\ttrain-logloss:0.21898\tvalid-logloss:0.22353\n[400]\ttrain-logloss:0.21493\tvalid-logloss:0.22134\n[500]\ttrain-logloss:0.21172\tvalid-logloss:0.22015\n[600]\ttrain-logloss:0.20897\tvalid-logloss:0.21936\n[700]\ttrain-logloss:0.20653\tvalid-logloss:0.21880\n[800]\ttrain-logloss:0.20419\tvalid-logloss:0.21840\n[900]\ttrain-logloss:0.20205\tvalid-logloss:0.21811\n[1000]\ttrain-logloss:0.20001\tvalid-logloss:0.21787\n[1100]\ttrain-logloss:0.19809\tvalid-logloss:0.21772\n[1200]\ttrain-logloss:0.19613\tvalid-logloss:0.21749\n[1300]\ttrain-logloss:0.19422\tvalid-logloss:0.21740\n[1400]\ttrain-logloss:0.19234\tvalid-logloss:0.21730\n[1500]\ttrain-logloss:0.19056\tvalid-logloss:0.21723\n[1600]\ttrain-logloss:0.18878\tvalid-logloss:0.21714\n[1700]\ttrain-logloss:0.18710\tvalid-logloss:0.21708\n[1800]\ttrain-logloss:0.18538\tvalid-logloss:0.21708\n[1839]\ttrain-logloss:0.18475\tvalid-logloss:0.21708\nKaggle Metric on valid set = 0.7926489920991127 \n\nKaggle Metric on all dataset = 0.8372377268545996 \n\n#########################\nOVERALL CV Kaggle Metric = 0.7888496155047777\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## CateBoost","metadata":{}},{"cell_type":"code","source":"# GET CATEG VARIABLES\ncat_features = [\"B_30\", \"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\ncateg = []\n#print(train.columns)\nfor col in train.columns :\n    if col not in ['customer_ID', 'target'] :\n        VAR = '_'.join(col.split('_')[:2])\n        if VAR in cat_features :\n            categ.append(col)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T10:18:24.629915Z","iopub.execute_input":"2022-08-31T10:18:24.631254Z","iopub.status.idle":"2022-08-31T10:18:24.638935Z","shell.execute_reply.started":"2022-08-31T10:18:24.631211Z","shell.execute_reply":"2022-08-31T10:18:24.63781Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"try :\n    del all_pool, pred, valid_pred\n    _ = gc.collect()\nexcept NameError :\n    pass","metadata":{"execution":{"iopub.status.busy":"2022-08-31T10:18:24.640572Z","iopub.execute_input":"2022-08-31T10:18:24.641772Z","iopub.status.idle":"2022-08-31T10:18:24.649482Z","shell.execute_reply.started":"2022-08-31T10:18:24.641733Z","shell.execute_reply":"2022-08-31T10:18:24.648213Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"oof = []\nskf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\nfor fold,(train_idx, valid_idx) in enumerate(skf.split(\n            train, train.target )):\n    print('#'*25)\n    print('### Fold',fold+1)\n    print('### Train size',len(train_idx),'Valid size',len(valid_idx))\n    print(f'### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...')\n    print('#'*25)\n    train_pool = Pool(train.loc[train_idx, FEATURES_2],\n                      train.loc[train_idx, 'target'],\n                      cat_features=categ\n                     )\n    valid_pool = Pool(train.loc[valid_idx, FEATURES_2],\n                      train.loc[valid_idx, 'target'],\n                      cat_features=categ\n                     )\n    model = CatBoostClassifier(iterations=9999,\n                               random_state=SEED,\n                               task_type=\"GPU\",\n                               loss_function = 'Logloss',\n                               learning_rate=0.05\n                               )\n    model.fit(train_pool, eval_set=valid_pool,\n              #od_type=\"Iter\",\n              early_stopping_rounds=100,\n              #od_wait=100,\n              verbose=100)\n    model.save_model(f'{ODIR}/CTB_nonan_features_v{VER}_fold{fold}.ctb')\n    valid_pred = model.predict_proba(valid_pool)[:,1]\n    val_acc = amex_metric_mod(train.loc[valid_idx, 'target'].values, valid_pred)\n    print('Kaggle Metric on valid set =',val_acc,'\\n')\n\n    df = train.loc[valid_idx, ['customer_ID','target'] ].copy()\n    df['oof_pred'] = valid_pred\n    oof.append( df )\n\n    del train_pool, valid_pool, df\n    _ = gc.collect()\n\n    all_pool = Pool(train[FEATURES_2],\n                    train['target'],\n                    cat_features=categ\n                     )\n    pred = model.predict_proba(all_pool)[:,1]\n    all_acc = amex_metric_mod(train['target'].values, pred)\n    print('Kaggle Metric on all dataset =',all_acc,'\\n')\n    #result_all = result_all.append({'model' : \"CateBoost\",\n    #                                'preprocessing' : \"huseyincot_nonan_feat\",\n    #                                'name' : f'CTB_nonan_features_v{VER}_fold{fold}',\n    #                                'y_valid_pred' : valid_pred,\n    #                                'valid_acc' : val_acc\n    #                                'y_pred' : pred,\n    #                                'acc' : all_acc\n    #                               },\n    #                               ignore_index=True\n    #                              )\n    del all_pool, pred, valid_pred\n    _ = gc.collect()\n\nprint('#'*25)\noof = pd.concat(oof,axis=0,ignore_index=True).set_index('customer_ID')\nacc = amex_metric_mod(oof.target.values, oof.oof_pred.values)\n#result_sum = result_sum.append({'model' : \"CateBoost\",\n#                                'preprocessing':\"huseyincot_all_feat\",\n#                                'name' : \"CTB_huseyincot_all_feat\",\n#                                'y_pred' : oof,\n#                                'acc': acc\n#                               },\n#                               ignore_index=True\n#                              )\nprint('OVERALL CV Kaggle Metric =',acc)\n\ndel oof, acc\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T10:18:24.651102Z","iopub.execute_input":"2022-08-31T10:18:24.651494Z","iopub.status.idle":"2022-08-31T10:47:54.556003Z","shell.execute_reply.started":"2022-08-31T10:18:24.651459Z","shell.execute_reply":"2022-08-31T10:47:54.55499Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"#########################\n### Fold 1\n### Train size 367130 Valid size 91783\n### Training with 100% fold data...\n#########################\n0:\tlearn: 0.6310359\ttest: 0.6309017\tbest: 0.6309017 (0)\ttotal: 154ms\tremaining: 25m 40s\n100:\tlearn: 0.2328865\ttest: 0.2349460\tbest: 0.2349460 (100)\ttotal: 10.8s\tremaining: 17m 35s\n200:\tlearn: 0.2254610\ttest: 0.2287104\tbest: 0.2287104 (200)\ttotal: 21.3s\tremaining: 17m 16s\n300:\tlearn: 0.2215497\ttest: 0.2260087\tbest: 0.2260087 (300)\ttotal: 32.5s\tremaining: 17m 27s\n400:\tlearn: 0.2188535\ttest: 0.2245013\tbest: 0.2245013 (400)\ttotal: 43s\tremaining: 17m 10s\n500:\tlearn: 0.2167790\ttest: 0.2236371\tbest: 0.2236371 (500)\ttotal: 53.6s\tremaining: 16m 56s\n600:\tlearn: 0.2150166\ttest: 0.2229886\tbest: 0.2229886 (600)\ttotal: 1m 4s\tremaining: 16m 52s\n700:\tlearn: 0.2134113\ttest: 0.2224972\tbest: 0.2224972 (700)\ttotal: 1m 15s\tremaining: 16m 38s\n800:\tlearn: 0.2118675\ttest: 0.2220633\tbest: 0.2220633 (800)\ttotal: 1m 25s\tremaining: 16m 26s\n900:\tlearn: 0.2104838\ttest: 0.2217320\tbest: 0.2217320 (900)\ttotal: 1m 37s\tremaining: 16m 20s\n1000:\tlearn: 0.2091678\ttest: 0.2214540\tbest: 0.2214540 (1000)\ttotal: 1m 47s\tremaining: 16m 7s\n1100:\tlearn: 0.2079007\ttest: 0.2212313\tbest: 0.2212293 (1099)\ttotal: 1m 58s\tremaining: 15m 55s\n1200:\tlearn: 0.2066677\ttest: 0.2210481\tbest: 0.2210481 (1200)\ttotal: 2m 9s\tremaining: 15m 48s\n1300:\tlearn: 0.2054490\ttest: 0.2208641\tbest: 0.2208621 (1298)\ttotal: 2m 19s\tremaining: 15m 35s\n1400:\tlearn: 0.2042752\ttest: 0.2206711\tbest: 0.2206711 (1400)\ttotal: 2m 30s\tremaining: 15m 23s\n1500:\tlearn: 0.2031618\ttest: 0.2205484\tbest: 0.2205484 (1500)\ttotal: 2m 41s\tremaining: 15m 15s\n1600:\tlearn: 0.2019828\ttest: 0.2204219\tbest: 0.2204183 (1596)\ttotal: 2m 52s\tremaining: 15m 3s\n1700:\tlearn: 0.2008047\ttest: 0.2202680\tbest: 0.2202680 (1700)\ttotal: 3m 2s\tremaining: 14m 51s\n1800:\tlearn: 0.1996843\ttest: 0.2201403\tbest: 0.2201390 (1799)\ttotal: 3m 13s\tremaining: 14m 41s\n1900:\tlearn: 0.1985786\ttest: 0.2200299\tbest: 0.2200299 (1900)\ttotal: 3m 24s\tremaining: 14m 30s\n2000:\tlearn: 0.1975439\ttest: 0.2199107\tbest: 0.2199105 (1999)\ttotal: 3m 34s\tremaining: 14m 18s\n2100:\tlearn: 0.1964528\ttest: 0.2197891\tbest: 0.2197835 (2095)\ttotal: 3m 46s\tremaining: 14m 10s\n2200:\tlearn: 0.1953774\ttest: 0.2196420\tbest: 0.2196420 (2200)\ttotal: 3m 56s\tremaining: 13m 59s\n2300:\tlearn: 0.1943732\ttest: 0.2196320\tbest: 0.2196124 (2291)\ttotal: 4m 7s\tremaining: 13m 47s\n2400:\tlearn: 0.1933249\ttest: 0.2195671\tbest: 0.2195635 (2399)\ttotal: 4m 18s\tremaining: 13m 37s\n2500:\tlearn: 0.1923068\ttest: 0.2195030\tbest: 0.2195027 (2498)\ttotal: 4m 28s\tremaining: 13m 26s\n2600:\tlearn: 0.1913038\ttest: 0.2194977\tbest: 0.2194749 (2532)\ttotal: 4m 39s\tremaining: 13m 14s\nbestTest = 0.2194748968\nbestIteration = 2532\nShrink model to first 2533 iterations.\nKaggle Metric on valid set = 0.7905721656194473 \n\nKaggle Metric on all dataset = 0.8337468858497039 \n\n#########################\n### Fold 2\n### Train size 367130 Valid size 91783\n### Training with 100% fold data...\n#########################\n0:\tlearn: 0.6314997\ttest: 0.6314755\tbest: 0.6314755 (0)\ttotal: 116ms\tremaining: 19m 24s\n100:\tlearn: 0.2332515\ttest: 0.2329641\tbest: 0.2329641 (100)\ttotal: 10.9s\tremaining: 17m 52s\n200:\tlearn: 0.2257758\ttest: 0.2267039\tbest: 0.2267039 (200)\ttotal: 21.6s\tremaining: 17m 33s\n300:\tlearn: 0.2219116\ttest: 0.2240909\tbest: 0.2240909 (300)\ttotal: 32.8s\tremaining: 17m 35s\n400:\tlearn: 0.2192318\ttest: 0.2226625\tbest: 0.2226625 (400)\ttotal: 43.3s\tremaining: 17m 15s\n500:\tlearn: 0.2171452\ttest: 0.2218263\tbest: 0.2218263 (500)\ttotal: 53.9s\tremaining: 17m 1s\n600:\tlearn: 0.2153199\ttest: 0.2212693\tbest: 0.2212693 (600)\ttotal: 1m 4s\tremaining: 16m 51s\n700:\tlearn: 0.2136898\ttest: 0.2207617\tbest: 0.2207617 (700)\ttotal: 1m 15s\tremaining: 16m 36s\n800:\tlearn: 0.2121765\ttest: 0.2204368\tbest: 0.2204346 (799)\ttotal: 1m 25s\tremaining: 16m 22s\n900:\tlearn: 0.2107859\ttest: 0.2201485\tbest: 0.2201485 (900)\ttotal: 1m 36s\tremaining: 16m 17s\n1000:\tlearn: 0.2094665\ttest: 0.2199103\tbest: 0.2199103 (1000)\ttotal: 1m 47s\tremaining: 16m 4s\n1100:\tlearn: 0.2082078\ttest: 0.2197350\tbest: 0.2197350 (1100)\ttotal: 1m 57s\tremaining: 15m 52s\n1200:\tlearn: 0.2069695\ttest: 0.2195398\tbest: 0.2195347 (1197)\ttotal: 2m 9s\tremaining: 15m 45s\n1300:\tlearn: 0.2057418\ttest: 0.2193449\tbest: 0.2193429 (1298)\ttotal: 2m 19s\tremaining: 15m 33s\n1400:\tlearn: 0.2045713\ttest: 0.2191863\tbest: 0.2191844 (1397)\ttotal: 2m 30s\tremaining: 15m 21s\n1500:\tlearn: 0.2033979\ttest: 0.2190800\tbest: 0.2190800 (1500)\ttotal: 2m 41s\tremaining: 15m 13s\n1600:\tlearn: 0.2022901\ttest: 0.2189272\tbest: 0.2189272 (1600)\ttotal: 2m 51s\tremaining: 15m 2s\n1700:\tlearn: 0.2011827\ttest: 0.2188024\tbest: 0.2188024 (1700)\ttotal: 3m 2s\tremaining: 14m 50s\n1800:\tlearn: 0.2001198\ttest: 0.2187362\tbest: 0.2187356 (1798)\ttotal: 3m 13s\tremaining: 14m 42s\n1900:\tlearn: 0.1989880\ttest: 0.2186772\tbest: 0.2186756 (1899)\ttotal: 3m 24s\tremaining: 14m 30s\n2000:\tlearn: 0.1979015\ttest: 0.2185824\tbest: 0.2185751 (1994)\ttotal: 3m 34s\tremaining: 14m 19s\n2100:\tlearn: 0.1968560\ttest: 0.2185070\tbest: 0.2185031 (2097)\ttotal: 3m 46s\tremaining: 14m 9s\n2200:\tlearn: 0.1957962\ttest: 0.2184086\tbest: 0.2184086 (2200)\ttotal: 3m 56s\tremaining: 13m 57s\n2300:\tlearn: 0.1947333\ttest: 0.2183738\tbest: 0.2183738 (2300)\ttotal: 4m 7s\tremaining: 13m 46s\n2400:\tlearn: 0.1937171\ttest: 0.2183151\tbest: 0.2183151 (2400)\ttotal: 4m 18s\tremaining: 13m 38s\n2500:\tlearn: 0.1927310\ttest: 0.2182881\tbest: 0.2182803 (2491)\ttotal: 4m 29s\tremaining: 13m 26s\n2600:\tlearn: 0.1917318\ttest: 0.2181809\tbest: 0.2181734 (2588)\ttotal: 4m 39s\tremaining: 13m 15s\n2700:\tlearn: 0.1907731\ttest: 0.2181768\tbest: 0.2181654 (2674)\ttotal: 4m 50s\tremaining: 13m 5s\n2800:\tlearn: 0.1898169\ttest: 0.2181532\tbest: 0.2181411 (2777)\ttotal: 5m 1s\tremaining: 12m 54s\nbestTest = 0.2181410569\nbestIteration = 2777\nShrink model to first 2778 iterations.\nKaggle Metric on valid set = 0.7902747886229592 \n\nKaggle Metric on all dataset = 0.8371871929257029 \n\n#########################\n### Fold 3\n### Train size 367130 Valid size 91783\n### Training with 100% fold data...\n#########################\n0:\tlearn: 0.6314622\ttest: 0.6316041\tbest: 0.6316041 (0)\ttotal: 121ms\tremaining: 20m 14s\n100:\tlearn: 0.2325229\ttest: 0.2356618\tbest: 0.2356618 (100)\ttotal: 11.3s\tremaining: 18m 28s\n200:\tlearn: 0.2249843\ttest: 0.2295182\tbest: 0.2295182 (200)\ttotal: 22s\tremaining: 17m 50s\n300:\tlearn: 0.2211301\ttest: 0.2270110\tbest: 0.2270110 (300)\ttotal: 33s\tremaining: 17m 43s\n400:\tlearn: 0.2183221\ttest: 0.2256202\tbest: 0.2256202 (400)\ttotal: 43.9s\tremaining: 17m 31s\n500:\tlearn: 0.2162491\ttest: 0.2247957\tbest: 0.2247957 (500)\ttotal: 54.5s\tremaining: 17m 12s\n600:\tlearn: 0.2144421\ttest: 0.2241990\tbest: 0.2241990 (600)\ttotal: 1m 5s\tremaining: 17m 4s\n700:\tlearn: 0.2128497\ttest: 0.2237712\tbest: 0.2237712 (700)\ttotal: 1m 16s\tremaining: 16m 50s\n800:\tlearn: 0.2113952\ttest: 0.2234419\tbest: 0.2234419 (800)\ttotal: 1m 26s\tremaining: 16m 36s\n900:\tlearn: 0.2100070\ttest: 0.2231477\tbest: 0.2231477 (900)\ttotal: 1m 37s\tremaining: 16m 29s\n1000:\tlearn: 0.2086813\ttest: 0.2229304\tbest: 0.2229304 (1000)\ttotal: 1m 48s\tremaining: 16m 15s\n1100:\tlearn: 0.2074191\ttest: 0.2227668\tbest: 0.2227668 (1100)\ttotal: 1m 58s\tremaining: 16m 1s\n1200:\tlearn: 0.2061521\ttest: 0.2226232\tbest: 0.2226232 (1200)\ttotal: 2m 10s\tremaining: 15m 53s\n1300:\tlearn: 0.2049471\ttest: 0.2224978\tbest: 0.2224955 (1295)\ttotal: 2m 20s\tremaining: 15m 41s\n1400:\tlearn: 0.2037701\ttest: 0.2223860\tbest: 0.2223860 (1400)\ttotal: 2m 31s\tremaining: 15m 28s\n1500:\tlearn: 0.2026260\ttest: 0.2222523\tbest: 0.2222483 (1498)\ttotal: 2m 42s\tremaining: 15m 18s\n1600:\tlearn: 0.2014468\ttest: 0.2221752\tbest: 0.2221746 (1597)\ttotal: 2m 52s\tremaining: 15m 5s\n1700:\tlearn: 0.2003380\ttest: 0.2220643\tbest: 0.2220576 (1694)\ttotal: 3m 3s\tremaining: 14m 53s\n1800:\tlearn: 0.1992538\ttest: 0.2219639\tbest: 0.2219639 (1800)\ttotal: 3m 14s\tremaining: 14m 44s\n1900:\tlearn: 0.1981789\ttest: 0.2219092\tbest: 0.2219092 (1900)\ttotal: 3m 24s\tremaining: 14m 31s\n2000:\tlearn: 0.1971734\ttest: 0.2218196\tbest: 0.2218165 (1987)\ttotal: 3m 35s\tremaining: 14m 20s\n2100:\tlearn: 0.1961467\ttest: 0.2217871\tbest: 0.2217871 (2100)\ttotal: 3m 46s\tremaining: 14m 11s\n2200:\tlearn: 0.1951109\ttest: 0.2217262\tbest: 0.2217217 (2177)\ttotal: 3m 56s\tremaining: 13m 59s\n2300:\tlearn: 0.1940641\ttest: 0.2217105\tbest: 0.2217082 (2297)\ttotal: 4m 7s\tremaining: 13m 47s\n2400:\tlearn: 0.1930241\ttest: 0.2216585\tbest: 0.2216554 (2390)\ttotal: 4m 18s\tremaining: 13m 38s\n2500:\tlearn: 0.1920576\ttest: 0.2216194\tbest: 0.2216137 (2477)\ttotal: 4m 29s\tremaining: 13m 27s\n2600:\tlearn: 0.1910990\ttest: 0.2215963\tbest: 0.2215905 (2588)\ttotal: 4m 39s\tremaining: 13m 15s\n2700:\tlearn: 0.1900817\ttest: 0.2215864\tbest: 0.2215839 (2697)\ttotal: 4m 51s\tremaining: 13m 6s\n2800:\tlearn: 0.1891164\ttest: 0.2215456\tbest: 0.2215390 (2772)\ttotal: 5m 1s\tremaining: 12m 55s\n2900:\tlearn: 0.1881666\ttest: 0.2215089\tbest: 0.2215089 (2900)\ttotal: 5m 12s\tremaining: 12m 44s\n3000:\tlearn: 0.1872189\ttest: 0.2214743\tbest: 0.2214743 (3000)\ttotal: 5m 23s\tremaining: 12m 34s\n3100:\tlearn: 0.1862934\ttest: 0.2215004\tbest: 0.2214696 (3003)\ttotal: 5m 33s\tremaining: 12m 22s\nbestTest = 0.2214696238\nbestIteration = 3003\nShrink model to first 3004 iterations.\nKaggle Metric on valid set = 0.7877754520931082 \n\nKaggle Metric on all dataset = 0.8404415877809063 \n\n#########################\n### Fold 4\n### Train size 367131 Valid size 91782\n### Training with 100% fold data...\n#########################\n0:\tlearn: 0.6320484\ttest: 0.6322356\tbest: 0.6322356 (0)\ttotal: 117ms\tremaining: 19m 30s\n100:\tlearn: 0.2325934\ttest: 0.2359279\tbest: 0.2359279 (100)\ttotal: 10.9s\tremaining: 17m 45s\n200:\tlearn: 0.2249779\ttest: 0.2297693\tbest: 0.2297693 (200)\ttotal: 22.4s\tremaining: 18m 9s\n300:\tlearn: 0.2211186\ttest: 0.2272584\tbest: 0.2272584 (300)\ttotal: 33s\tremaining: 17m 42s\n400:\tlearn: 0.2185073\ttest: 0.2259140\tbest: 0.2259140 (400)\ttotal: 43.6s\tremaining: 17m 22s\n500:\tlearn: 0.2164392\ttest: 0.2250365\tbest: 0.2250365 (500)\ttotal: 54.5s\tremaining: 17m 13s\n600:\tlearn: 0.2146530\ttest: 0.2244618\tbest: 0.2244618 (600)\ttotal: 1m 5s\tremaining: 16m 57s\n700:\tlearn: 0.2130580\ttest: 0.2240348\tbest: 0.2240348 (700)\ttotal: 1m 15s\tremaining: 16m 43s\n800:\tlearn: 0.2115510\ttest: 0.2236637\tbest: 0.2236637 (800)\ttotal: 1m 26s\tremaining: 16m 37s\n900:\tlearn: 0.2102316\ttest: 0.2234336\tbest: 0.2234336 (900)\ttotal: 1m 37s\tremaining: 16m 23s\n1000:\tlearn: 0.2089315\ttest: 0.2231685\tbest: 0.2231650 (999)\ttotal: 1m 47s\tremaining: 16m 10s\n1100:\tlearn: 0.2076522\ttest: 0.2229629\tbest: 0.2229629 (1100)\ttotal: 1m 59s\tremaining: 16m 4s\n1200:\tlearn: 0.2064313\ttest: 0.2227849\tbest: 0.2227845 (1199)\ttotal: 2m 9s\tremaining: 15m 50s\n1300:\tlearn: 0.2052172\ttest: 0.2225871\tbest: 0.2225870 (1298)\ttotal: 2m 20s\tremaining: 15m 39s\n1400:\tlearn: 0.2040645\ttest: 0.2225032\tbest: 0.2225022 (1399)\ttotal: 2m 31s\tremaining: 15m 31s\n1500:\tlearn: 0.2028543\ttest: 0.2224008\tbest: 0.2224008 (1500)\ttotal: 2m 42s\tremaining: 15m 18s\n1600:\tlearn: 0.2017626\ttest: 0.2222626\tbest: 0.2222626 (1600)\ttotal: 2m 52s\tremaining: 15m 6s\n1700:\tlearn: 0.2006720\ttest: 0.2221404\tbest: 0.2221404 (1700)\ttotal: 3m 4s\tremaining: 14m 58s\n1800:\tlearn: 0.1995394\ttest: 0.2220737\tbest: 0.2220715 (1798)\ttotal: 3m 14s\tremaining: 14m 46s\n1900:\tlearn: 0.1984319\ttest: 0.2220273\tbest: 0.2220151 (1898)\ttotal: 3m 25s\tremaining: 14m 35s\n2000:\tlearn: 0.1973774\ttest: 0.2219595\tbest: 0.2219529 (1973)\ttotal: 3m 36s\tremaining: 14m 26s\n2100:\tlearn: 0.1963509\ttest: 0.2218632\tbest: 0.2218611 (2099)\ttotal: 3m 47s\tremaining: 14m 15s\n2200:\tlearn: 0.1953335\ttest: 0.2217704\tbest: 0.2217704 (2200)\ttotal: 3m 58s\tremaining: 14m 4s\n2300:\tlearn: 0.1943003\ttest: 0.2216865\tbest: 0.2216865 (2300)\ttotal: 4m 9s\tremaining: 13m 54s\n2400:\tlearn: 0.1932046\ttest: 0.2216466\tbest: 0.2216457 (2395)\ttotal: 4m 20s\tremaining: 13m 43s\n2500:\tlearn: 0.1921939\ttest: 0.2215862\tbest: 0.2215845 (2499)\ttotal: 4m 31s\tremaining: 13m 33s\n2600:\tlearn: 0.1911304\ttest: 0.2215591\tbest: 0.2215528 (2595)\ttotal: 4m 42s\tremaining: 13m 22s\n2700:\tlearn: 0.1901283\ttest: 0.2214476\tbest: 0.2214470 (2698)\ttotal: 4m 52s\tremaining: 13m 11s\n2800:\tlearn: 0.1891465\ttest: 0.2214131\tbest: 0.2214106 (2787)\ttotal: 5m 3s\tremaining: 13m 1s\n2900:\tlearn: 0.1882098\ttest: 0.2213753\tbest: 0.2213674 (2867)\ttotal: 5m 14s\tremaining: 12m 49s\n3000:\tlearn: 0.1872293\ttest: 0.2213514\tbest: 0.2213471 (2951)\ttotal: 5m 25s\tremaining: 12m 38s\n3100:\tlearn: 0.1863062\ttest: 0.2212919\tbest: 0.2212919 (3100)\ttotal: 5m 36s\tremaining: 12m 28s\n3200:\tlearn: 0.1853962\ttest: 0.2212689\tbest: 0.2212671 (3199)\ttotal: 5m 47s\tremaining: 12m 17s\n3300:\tlearn: 0.1844828\ttest: 0.2212681\tbest: 0.2212599 (3202)\ttotal: 5m 57s\tremaining: 12m 5s\nbestTest = 0.2212598535\nbestIteration = 3202\nShrink model to first 3203 iterations.\nKaggle Metric on valid set = 0.785758297905679 \n\nKaggle Metric on all dataset = 0.8431729355568007 \n\n#########################\n### Fold 5\n### Train size 367131 Valid size 91782\n### Training with 100% fold data...\n#########################\n0:\tlearn: 0.6324140\ttest: 0.6323337\tbest: 0.6323337 (0)\ttotal: 112ms\tremaining: 18m 41s\n100:\tlearn: 0.2337221\ttest: 0.2333109\tbest: 0.2333109 (100)\ttotal: 11.1s\tremaining: 18m 11s\n200:\tlearn: 0.2260432\ttest: 0.2265843\tbest: 0.2265843 (200)\ttotal: 21.8s\tremaining: 17m 43s\n300:\tlearn: 0.2221377\ttest: 0.2238103\tbest: 0.2238103 (300)\ttotal: 32.5s\tremaining: 17m 28s\n400:\tlearn: 0.2194767\ttest: 0.2223548\tbest: 0.2223548 (400)\ttotal: 43.8s\tremaining: 17m 27s\n500:\tlearn: 0.2173135\ttest: 0.2214610\tbest: 0.2214610 (500)\ttotal: 54.3s\tremaining: 17m 10s\n600:\tlearn: 0.2155381\ttest: 0.2208580\tbest: 0.2208580 (600)\ttotal: 1m 4s\tremaining: 16m 53s\n700:\tlearn: 0.2138518\ttest: 0.2202982\tbest: 0.2202982 (700)\ttotal: 1m 15s\tremaining: 16m 47s\n800:\tlearn: 0.2123742\ttest: 0.2199141\tbest: 0.2199081 (798)\ttotal: 1m 26s\tremaining: 16m 34s\n900:\tlearn: 0.2109261\ttest: 0.2195702\tbest: 0.2195660 (898)\ttotal: 1m 37s\tremaining: 16m 21s\n1000:\tlearn: 0.2096055\ttest: 0.2192244\tbest: 0.2192239 (999)\ttotal: 1m 48s\tremaining: 16m 16s\n1100:\tlearn: 0.2083166\ttest: 0.2189852\tbest: 0.2189852 (1100)\ttotal: 1m 59s\tremaining: 16m 3s\n1200:\tlearn: 0.2070423\ttest: 0.2187927\tbest: 0.2187899 (1199)\ttotal: 2m 9s\tremaining: 15m 51s\n1300:\tlearn: 0.2058243\ttest: 0.2186346\tbest: 0.2186324 (1299)\ttotal: 2m 20s\tremaining: 15m 42s\n1400:\tlearn: 0.2046263\ttest: 0.2185052\tbest: 0.2185022 (1397)\ttotal: 2m 31s\tremaining: 15m 30s\n1500:\tlearn: 0.2034374\ttest: 0.2183295\tbest: 0.2183295 (1500)\ttotal: 2m 42s\tremaining: 15m 17s\n1600:\tlearn: 0.2023219\ttest: 0.2182359\tbest: 0.2182343 (1599)\ttotal: 2m 53s\tremaining: 15m 8s\n1700:\tlearn: 0.2012183\ttest: 0.2181698\tbest: 0.2181694 (1699)\ttotal: 3m 3s\tremaining: 14m 56s\n1800:\tlearn: 0.2001006\ttest: 0.2180615\tbest: 0.2180605 (1785)\ttotal: 3m 14s\tremaining: 14m 44s\n1900:\tlearn: 0.1990141\ttest: 0.2179908\tbest: 0.2179886 (1899)\ttotal: 3m 25s\tremaining: 14m 34s\n2000:\tlearn: 0.1979571\ttest: 0.2179065\tbest: 0.2179003 (1995)\ttotal: 3m 35s\tremaining: 14m 22s\n2100:\tlearn: 0.1968690\ttest: 0.2177897\tbest: 0.2177819 (2088)\ttotal: 3m 46s\tremaining: 14m 11s\n2200:\tlearn: 0.1958374\ttest: 0.2177185\tbest: 0.2177156 (2199)\ttotal: 3m 57s\tremaining: 14m 2s\n2300:\tlearn: 0.1948371\ttest: 0.2176585\tbest: 0.2176521 (2296)\ttotal: 4m 8s\tremaining: 13m 51s\n2400:\tlearn: 0.1938240\ttest: 0.2176158\tbest: 0.2176153 (2399)\ttotal: 4m 19s\tremaining: 13m 39s\n2500:\tlearn: 0.1927722\ttest: 0.2175723\tbest: 0.2175694 (2498)\ttotal: 4m 30s\tremaining: 13m 30s\n2600:\tlearn: 0.1918219\ttest: 0.2175162\tbest: 0.2175162 (2600)\ttotal: 4m 40s\tremaining: 13m 19s\n2700:\tlearn: 0.1907844\ttest: 0.2174718\tbest: 0.2174552 (2684)\ttotal: 4m 51s\tremaining: 13m 8s\n2800:\tlearn: 0.1898187\ttest: 0.2174468\tbest: 0.2174382 (2744)\ttotal: 5m 2s\tremaining: 12m 58s\nbestTest = 0.2174381704\nbestIteration = 2744\nShrink model to first 2745 iterations.\nKaggle Metric on valid set = 0.7937585266671012 \n\nKaggle Metric on all dataset = 0.8368998532019585 \n\n#########################\nOVERALL CV Kaggle Metric = 0.7895673878803888\n","output_type":"stream"}]},{"cell_type":"code","source":"del train\n_=gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T10:47:54.55735Z","iopub.execute_input":"2022-08-31T10:47:54.558526Z","iopub.status.idle":"2022-08-31T10:47:54.688754Z","shell.execute_reply.started":"2022-08-31T10:47:54.55849Z","shell.execute_reply":"2022-08-31T10:47:54.687569Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# Features importances","metadata":{}},{"cell_type":"markdown","source":"A selection of most important features is done using the drop columns importances method.\nThe goal is to use only most important features for the prediction.","metadata":{}},{"cell_type":"markdown","source":"## Load data","metadata":{}},{"cell_type":"code","source":"train = read_file(path = TRAIN_PATH)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T10:47:54.690095Z","iopub.execute_input":"2022-08-31T10:47:54.690873Z","iopub.status.idle":"2022-08-31T10:48:14.720608Z","shell.execute_reply.started":"2022-08-31T10:47:54.690834Z","shell.execute_reply":"2022-08-31T10:48:14.71957Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"shape of data: (5531451, 190)\n","output_type":"stream"}]},{"cell_type":"code","source":"train = process_and_feature_engineer(train)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T10:48:14.722082Z","iopub.execute_input":"2022-08-31T10:48:14.722709Z","iopub.status.idle":"2022-08-31T10:48:16.978476Z","shell.execute_reply.started":"2022-08-31T10:48:14.722667Z","shell.execute_reply":"2022-08-31T10:48:16.977465Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"shape after engineering (458913, 918)\n","output_type":"stream"}]},{"cell_type":"code","source":"# ADD TARGETS\ntargets = cudf.read_csv('../input/amex-default-prediction/train_labels.csv')\ntargets['customer_ID'] = targets['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\ntargets = targets.set_index('customer_ID')\ntrain = train.merge(targets, left_index=True, right_index=True, how='left')\ntrain.target = train.target.astype('int8')\ndel targets\n\n# NEEDED TO MAKE CV DETERMINISTIC (cudf merge above randomly shuffles rows)\ntrain = train.sort_index().reset_index()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T10:48:16.98179Z","iopub.execute_input":"2022-08-31T10:48:16.982075Z","iopub.status.idle":"2022-08-31T10:48:17.917596Z","shell.execute_reply.started":"2022-08-31T10:48:16.982049Z","shell.execute_reply":"2022-08-31T10:48:17.916545Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"Because of the important size of the train set and in order to spped up the selection,\nwe select only 1/400 of rows.","metadata":{}},{"cell_type":"code","source":"train = train.loc[range(int(len(train)/400))]\ntrain=train.to_pandas()\nprint(train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T10:48:17.919621Z","iopub.execute_input":"2022-08-31T10:48:17.920011Z","iopub.status.idle":"2022-08-31T10:48:18.458534Z","shell.execute_reply.started":"2022-08-31T10:48:17.919975Z","shell.execute_reply":"2022-08-31T10:48:18.457266Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"(1147, 920)\n","output_type":"stream"}]},{"cell_type":"code","source":"FEATURES_tmp = train.columns[1:-1]","metadata":{"execution":{"iopub.status.busy":"2022-08-31T10:48:18.46025Z","iopub.execute_input":"2022-08-31T10:48:18.460794Z","iopub.status.idle":"2022-08-31T10:48:18.466161Z","shell.execute_reply.started":"2022-08-31T10:48:18.460756Z","shell.execute_reply":"2022-08-31T10:48:18.465038Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"## Select features","metadata":{}},{"cell_type":"code","source":"def dropcol_importances(rf_model, data, labels):\n    \"\"\"\n    Function to calculate features importances with a random forest model\n    \"\"\"\n    rf_model_ = deepcopy(rf_model)\n    rf_model_.random_state = 999\n    rf_model_.fit(data, labels)\n    baseline = rf_model_.oob_score_\n    imp = []\n    for i, column in enumerate(data.columns):\n        print(f\"{i}/{len(data.columns)}\", end=\"\\r\")\n        data_tmp = data.drop(column, axis=1)\n        rf_model_ = deepcopy(rf_model)\n        rf_model_.random_state = 999\n        rf_model_.fit(data_tmp, labels)\n        oob = rf_model_.oob_score_\n        imp.append(baseline - oob)\n    imp = np.array(imp)\n    out = pd.DataFrame(\n            data={'Feature':data.columns,\n                  'Importance':imp})\n    out = out.set_index('Feature')\n    out = out.sort_values('Importance', ascending=True)\n    return out","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:05:21.524703Z","iopub.execute_input":"2022-08-31T11:05:21.525064Z","iopub.status.idle":"2022-08-31T11:05:21.534742Z","shell.execute_reply.started":"2022-08-31T11:05:21.525034Z","shell.execute_reply":"2022-08-31T11:05:21.532341Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"rf = RandomForestClassifier(\n         n_estimators=100,\n         # better generality with 5\n         min_samples_leaf=5,\n         n_jobs=-1,\n         oob_score=True)\nrf.fit(train[FEATURES_tmp], train['target']) # rf must be pre-trained","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:05:23.019542Z","iopub.execute_input":"2022-08-31T11:05:23.019909Z","iopub.status.idle":"2022-08-31T11:05:23.769965Z","shell.execute_reply.started":"2022-08-31T11:05:23.019879Z","shell.execute_reply":"2022-08-31T11:05:23.769085Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"RandomForestClassifier(min_samples_leaf=5, n_jobs=-1, oob_score=True)"},"metadata":{}}]},{"cell_type":"code","source":"dc_imp = dropcol_importances(rf,train[FEATURES_tmp] , train['target'])","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:05:24.923371Z","iopub.execute_input":"2022-08-31T11:05:24.923957Z","iopub.status.idle":"2022-08-31T11:16:21.799878Z","shell.execute_reply.started":"2022-08-31T11:05:24.923923Z","shell.execute_reply":"2022-08-31T11:16:21.79892Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"917/918\r","output_type":"stream"}]},{"cell_type":"code","source":"dc_imp","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:16:21.802083Z","iopub.execute_input":"2022-08-31T11:16:21.80259Z","iopub.status.idle":"2022-08-31T11:16:21.817467Z","shell.execute_reply.started":"2022-08-31T11:16:21.802546Z","shell.execute_reply":"2022-08-31T11:16:21.816342Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"              Importance\nFeature                 \nS_20_min       -0.012206\nS_20_last      -0.012206\nS_20_max       -0.010462\nD_64_count     -0.010462\nD_64_nunique   -0.010462\n...                  ...\nB_21_mean       0.013078\nB_22_std        0.013949\nS_13_min        0.014821\nS_13_mean       0.015693\nS_13_std        0.017437\n\n[918 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Importance</th>\n    </tr>\n    <tr>\n      <th>Feature</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>S_20_min</th>\n      <td>-0.012206</td>\n    </tr>\n    <tr>\n      <th>S_20_last</th>\n      <td>-0.012206</td>\n    </tr>\n    <tr>\n      <th>S_20_max</th>\n      <td>-0.010462</td>\n    </tr>\n    <tr>\n      <th>D_64_count</th>\n      <td>-0.010462</td>\n    </tr>\n    <tr>\n      <th>D_64_nunique</th>\n      <td>-0.010462</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>B_21_mean</th>\n      <td>0.013078</td>\n    </tr>\n    <tr>\n      <th>B_22_std</th>\n      <td>0.013949</td>\n    </tr>\n    <tr>\n      <th>S_13_min</th>\n      <td>0.014821</td>\n    </tr>\n    <tr>\n      <th>S_13_mean</th>\n      <td>0.015693</td>\n    </tr>\n    <tr>\n      <th>S_13_std</th>\n      <td>0.017437</td>\n    </tr>\n  </tbody>\n</table>\n<p>918 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"The effect of each features on the accuracy is plot here","metadata":{}},{"cell_type":"code","source":"dc_imp.plot.barh()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:16:21.819192Z","iopub.execute_input":"2022-08-31T11:16:21.819831Z","iopub.status.idle":"2022-08-31T11:16:31.414499Z","shell.execute_reply.started":"2022-08-31T11:16:21.81979Z","shell.execute_reply":"2022-08-31T11:16:31.413335Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:ylabel='Feature'>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"Only features with an importance > 0 are conserved","metadata":{}},{"cell_type":"code","source":"dc_imp[dc_imp[\"Importance\"]>0]","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:16:31.417416Z","iopub.execute_input":"2022-08-31T11:16:31.417791Z","iopub.status.idle":"2022-08-31T11:16:31.43159Z","shell.execute_reply.started":"2022-08-31T11:16:31.417754Z","shell.execute_reply":"2022-08-31T11:16:31.430323Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"           Importance\nFeature              \nB_2_max      0.000872\nD_103_min    0.000872\nS_7_last     0.000872\nB_12_last    0.000872\nR_10_std     0.000872\n...               ...\nB_21_mean    0.013078\nB_22_std     0.013949\nS_13_min     0.014821\nS_13_mean    0.015693\nS_13_std     0.017437\n\n[574 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Importance</th>\n    </tr>\n    <tr>\n      <th>Feature</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>B_2_max</th>\n      <td>0.000872</td>\n    </tr>\n    <tr>\n      <th>D_103_min</th>\n      <td>0.000872</td>\n    </tr>\n    <tr>\n      <th>S_7_last</th>\n      <td>0.000872</td>\n    </tr>\n    <tr>\n      <th>B_12_last</th>\n      <td>0.000872</td>\n    </tr>\n    <tr>\n      <th>R_10_std</th>\n      <td>0.000872</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>B_21_mean</th>\n      <td>0.013078</td>\n    </tr>\n    <tr>\n      <th>B_22_std</th>\n      <td>0.013949</td>\n    </tr>\n    <tr>\n      <th>S_13_min</th>\n      <td>0.014821</td>\n    </tr>\n    <tr>\n      <th>S_13_mean</th>\n      <td>0.015693</td>\n    </tr>\n    <tr>\n      <th>S_13_std</th>\n      <td>0.017437</td>\n    </tr>\n  </tbody>\n</table>\n<p>574 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"FEATURES_3 = dc_imp[dc_imp[\"Importance\"]>0].index.to_list()\nwith open(ODIR+'/all_features_3.pkl', 'wb') as ofile :\n    pickle.dump(FEATURES_3, ofile)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:16:31.433816Z","iopub.execute_input":"2022-08-31T11:16:31.434225Z","iopub.status.idle":"2022-08-31T11:16:31.441798Z","shell.execute_reply.started":"2022-08-31T11:16:31.434179Z","shell.execute_reply":"2022-08-31T11:16:31.440748Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"MODEL_PATH = \"../input/amex-output-echesneau\"\nif os.path.isfile(MODEL_PATH+\"/all_features_3.pkl\") :\n    with open(MODEL_PATH+\"/all_features_3.pkl\", 'rb') as f :\n        FEATURES_3 = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:16:31.443198Z","iopub.execute_input":"2022-08-31T11:16:31.44431Z","iopub.status.idle":"2022-08-31T11:16:31.463577Z","shell.execute_reply.started":"2022-08-31T11:16:31.444221Z","shell.execute_reply":"2022-08-31T11:16:31.462747Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"markdown","source":"## prepare data for modelization","metadata":{}},{"cell_type":"markdown","source":"The same processing is then applY.","metadata":{}},{"cell_type":"code","source":"train = read_file(path = TRAIN_PATH)\ntrain = process_and_feature_engineer(train)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:16:31.464628Z","iopub.execute_input":"2022-08-31T11:16:31.466493Z","iopub.status.idle":"2022-08-31T11:16:35.466056Z","shell.execute_reply.started":"2022-08-31T11:16:31.46646Z","shell.execute_reply":"2022-08-31T11:16:35.464959Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"shape of data: (5531451, 190)\nshape after engineering (458913, 918)\n","output_type":"stream"}]},{"cell_type":"code","source":"# ADD TARGETS\ntargets = cudf.read_csv('../input/amex-default-prediction/train_labels.csv')\ntargets['customer_ID'] = targets['customer_ID'].str[-16:].str.hex_to_int().astype('int64')\ntargets = targets.set_index('customer_ID')\ntrain = train.merge(targets, left_index=True, right_index=True, how='left')\ntrain.target = train.target.astype('int8')\ndel targets\n\n# NEEDED TO MAKE CV DETERMINISTIC (cudf merge above randomly shuffles rows)\ntrain = train.sort_index().reset_index()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:16:35.471709Z","iopub.execute_input":"2022-08-31T11:16:35.474198Z","iopub.status.idle":"2022-08-31T11:16:36.422831Z","shell.execute_reply.started":"2022-08-31T11:16:35.474162Z","shell.execute_reply":"2022-08-31T11:16:36.421832Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"## XGBoost","metadata":{}},{"cell_type":"code","source":"train = train.to_pandas() # free GPU memory\nTRAIN_SUBSAMPLE = 1.0\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:16:36.425634Z","iopub.execute_input":"2022-08-31T11:16:36.426223Z","iopub.status.idle":"2022-08-31T11:16:39.898898Z","shell.execute_reply.started":"2022-08-31T11:16:36.426176Z","shell.execute_reply":"2022-08-31T11:16:39.897777Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"90"},"metadata":{}}]},{"cell_type":"code","source":"print('XGB Version',xgb.__version__)\n\n# XGB MODEL PARAMETERS\nxgb_parms = {\n    'max_depth':4,\n    'learning_rate':0.05,\n    'subsample':0.8,\n    'colsample_bytree':0.6,\n    'eval_metric':'logloss',\n    'objective':'binary:logistic',\n    'tree_method':'gpu_hist',\n    'predictor':'gpu_predictor',\n    'random_state':SEED\n}","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:16:39.90235Z","iopub.execute_input":"2022-08-31T11:16:39.902741Z","iopub.status.idle":"2022-08-31T11:16:39.909174Z","shell.execute_reply.started":"2022-08-31T11:16:39.902699Z","shell.execute_reply":"2022-08-31T11:16:39.908044Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"XGB Version 1.6.1\n","output_type":"stream"}]},{"cell_type":"code","source":"oof = []\nskf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\nfor fold,(train_idx, valid_idx) in enumerate(skf.split(\n            train, train.target )):\n    print('#'*25)\n    print('### Fold',fold+1)\n    print('### Train size',len(train_idx),'Valid size',len(valid_idx))\n    print(f'### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...')\n    print('#'*25)\n    dtrain = xgb.DMatrix(data=train.loc[train_idx, FEATURES_3], \\\n                        label=train.loc[train_idx, 'target'])\n    dvalid = xgb.DMatrix(data=train.loc[valid_idx, FEATURES_3], \\\n                         label=train.loc[valid_idx, 'target'])\n    model = xgb.train(xgb_parms,\n                      dtrain=dtrain,\n                      evals=[(dtrain,'train'),(dvalid,'valid')],\n                      num_boost_round=9999,\n                      #num_boost_round=99,\n                      early_stopping_rounds=100,\n                      verbose_eval=100)\n    model.save_model(f'{ODIR}/XGB_dc0_features_v{VER}_fold{fold}.xgb')\n    valid_pred = model.predict(dvalid)\n    val_acc = amex_metric_mod(train.loc[valid_idx, 'target'].values, valid_pred)\n    print('Kaggle Metric on valid set =',val_acc,'\\n')\n\n    df = train.loc[valid_idx, ['customer_ID','target'] ].copy()\n    df['oof_pred'] = valid_pred\n    oof.append( df )\n\n    del dtrain, dvalid, df\n    _ = gc.collect()\n\n    dall = xgb.DMatrix(data=train[FEATURES_3], label=train['target'])\n    pred = model.predict(dall)\n    all_acc = amex_metric_mod(train['target'].values, pred)\n    print('Kaggle Metric on all dataset =',all_acc,'\\n')\n    #result_all = result_all.append({'model' : \"XGBoost\",\n    #                                'preprocessing' : \"huseyincot_dc0_feat\",\n    #                                'name' : f'XGB_dc0_features_v{VER}_fold{fold}',\n    #                                'y_valid_pred' : valid_pred,\n    #                                'valid_acc' : val_acc,\n    #                                'y_pred' : pred,\n    #                                'acc' : all_acc\n    #                               },\n    #                               ignore_index=True\n    #                              )\n    del dall, pred, valid_pred\n    _ = gc.collect()\nprint('#'*25)\noof = pd.concat(oof,axis=0,ignore_index=True).set_index('customer_ID')\nacc = amex_metric_mod(oof.target.values, oof.oof_pred.values)\n#result_sum = result_sum.append({'model' : \"XGBoost\",\n#                                'preprocessing':\"huseyincot_dc0_feat\",\n#                                'name' : \"XGBoost_huseyincot_dc0_feat\",\n#                                'y_pred' : oof,\n#                                'acc': acc\n#                              },\n#                               ignore_index=True\n#                              )\nprint('OVERALL CV Kaggle Metric =',acc)\n\ndel oof, acc\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:16:39.911095Z","iopub.execute_input":"2022-08-31T11:16:39.91164Z","iopub.status.idle":"2022-08-31T11:22:28.733371Z","shell.execute_reply.started":"2022-08-31T11:16:39.911601Z","shell.execute_reply":"2022-08-31T11:22:28.732339Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"#########################\n### Fold 1\n### Train size 367130 Valid size 91783\n### Training with 100% fold data...\n#########################\n[0]\ttrain-logloss:0.66208\tvalid-logloss:0.66215\n[100]\ttrain-logloss:0.23774\tvalid-logloss:0.24044\n[200]\ttrain-logloss:0.22381\tvalid-logloss:0.22898\n[300]\ttrain-logloss:0.21815\tvalid-logloss:0.22516\n[400]\ttrain-logloss:0.21436\tvalid-logloss:0.22322\n[500]\ttrain-logloss:0.21139\tvalid-logloss:0.22206\n[600]\ttrain-logloss:0.20885\tvalid-logloss:0.22138\n[700]\ttrain-logloss:0.20657\tvalid-logloss:0.22080\n[800]\ttrain-logloss:0.20445\tvalid-logloss:0.22044\n[900]\ttrain-logloss:0.20238\tvalid-logloss:0.22012\n[1000]\ttrain-logloss:0.20036\tvalid-logloss:0.21988\n[1100]\ttrain-logloss:0.19849\tvalid-logloss:0.21970\n[1200]\ttrain-logloss:0.19671\tvalid-logloss:0.21951\n[1300]\ttrain-logloss:0.19498\tvalid-logloss:0.21944\n[1400]\ttrain-logloss:0.19326\tvalid-logloss:0.21941\n[1500]\ttrain-logloss:0.19155\tvalid-logloss:0.21937\n[1600]\ttrain-logloss:0.18988\tvalid-logloss:0.21930\n[1700]\ttrain-logloss:0.18831\tvalid-logloss:0.21923\n[1800]\ttrain-logloss:0.18668\tvalid-logloss:0.21916\n[1900]\ttrain-logloss:0.18509\tvalid-logloss:0.21914\n[2000]\ttrain-logloss:0.18356\tvalid-logloss:0.21911\n[2100]\ttrain-logloss:0.18202\tvalid-logloss:0.21908\n[2200]\ttrain-logloss:0.18054\tvalid-logloss:0.21910\n[2278]\ttrain-logloss:0.17940\tvalid-logloss:0.21910\nKaggle Metric on valid set = 0.7897556994591913 \n\nKaggle Metric on all dataset = 0.8455403138801353 \n\n#########################\n### Fold 2\n### Train size 367130 Valid size 91783\n### Training with 100% fold data...\n#########################\n[0]\ttrain-logloss:0.66210\tvalid-logloss:0.66207\n[100]\ttrain-logloss:0.23811\tvalid-logloss:0.23878\n[200]\ttrain-logloss:0.22429\tvalid-logloss:0.22674\n[300]\ttrain-logloss:0.21860\tvalid-logloss:0.22300\n[400]\ttrain-logloss:0.21481\tvalid-logloss:0.22115\n[500]\ttrain-logloss:0.21185\tvalid-logloss:0.22004\n[600]\ttrain-logloss:0.20927\tvalid-logloss:0.21931\n[700]\ttrain-logloss:0.20696\tvalid-logloss:0.21890\n[800]\ttrain-logloss:0.20475\tvalid-logloss:0.21851\n[900]\ttrain-logloss:0.20268\tvalid-logloss:0.21821\n[1000]\ttrain-logloss:0.20068\tvalid-logloss:0.21804\n[1100]\ttrain-logloss:0.19877\tvalid-logloss:0.21787\n[1200]\ttrain-logloss:0.19693\tvalid-logloss:0.21780\n[1300]\ttrain-logloss:0.19514\tvalid-logloss:0.21770\n[1400]\ttrain-logloss:0.19339\tvalid-logloss:0.21762\n[1500]\ttrain-logloss:0.19167\tvalid-logloss:0.21755\n[1600]\ttrain-logloss:0.19000\tvalid-logloss:0.21754\n[1700]\ttrain-logloss:0.18832\tvalid-logloss:0.21747\n[1800]\ttrain-logloss:0.18673\tvalid-logloss:0.21746\n[1900]\ttrain-logloss:0.18517\tvalid-logloss:0.21749\n[1921]\ttrain-logloss:0.18486\tvalid-logloss:0.21749\nKaggle Metric on valid set = 0.7932497820037796 \n\nKaggle Metric on all dataset = 0.8390241012038568 \n\n#########################\n### Fold 3\n### Train size 367130 Valid size 91783\n### Training with 100% fold data...\n#########################\n[0]\ttrain-logloss:0.66209\tvalid-logloss:0.66220\n[100]\ttrain-logloss:0.23750\tvalid-logloss:0.24152\n[200]\ttrain-logloss:0.22347\tvalid-logloss:0.23003\n[300]\ttrain-logloss:0.21769\tvalid-logloss:0.22644\n[400]\ttrain-logloss:0.21387\tvalid-logloss:0.22469\n[500]\ttrain-logloss:0.21089\tvalid-logloss:0.22372\n[600]\ttrain-logloss:0.20840\tvalid-logloss:0.22312\n[700]\ttrain-logloss:0.20601\tvalid-logloss:0.22265\n[800]\ttrain-logloss:0.20388\tvalid-logloss:0.22239\n[900]\ttrain-logloss:0.20184\tvalid-logloss:0.22214\n[1000]\ttrain-logloss:0.19990\tvalid-logloss:0.22196\n[1100]\ttrain-logloss:0.19806\tvalid-logloss:0.22176\n[1200]\ttrain-logloss:0.19617\tvalid-logloss:0.22162\n[1300]\ttrain-logloss:0.19441\tvalid-logloss:0.22156\n[1400]\ttrain-logloss:0.19263\tvalid-logloss:0.22152\n[1500]\ttrain-logloss:0.19093\tvalid-logloss:0.22146\n[1600]\ttrain-logloss:0.18923\tvalid-logloss:0.22145\n[1682]\ttrain-logloss:0.18788\tvalid-logloss:0.22147\nKaggle Metric on valid set = 0.7871633619412022 \n\nKaggle Metric on all dataset = 0.8323769424250551 \n\n#########################\n### Fold 4\n### Train size 367131 Valid size 91782\n### Training with 100% fold data...\n#########################\n[0]\ttrain-logloss:0.66206\tvalid-logloss:0.66220\n[100]\ttrain-logloss:0.23731\tvalid-logloss:0.24187\n[200]\ttrain-logloss:0.22341\tvalid-logloss:0.23019\n[300]\ttrain-logloss:0.21772\tvalid-logloss:0.22653\n[400]\ttrain-logloss:0.21393\tvalid-logloss:0.22471\n[500]\ttrain-logloss:0.21100\tvalid-logloss:0.22369\n[600]\ttrain-logloss:0.20843\tvalid-logloss:0.22302\n[700]\ttrain-logloss:0.20609\tvalid-logloss:0.22252\n[800]\ttrain-logloss:0.20392\tvalid-logloss:0.22219\n[900]\ttrain-logloss:0.20186\tvalid-logloss:0.22188\n[1000]\ttrain-logloss:0.19982\tvalid-logloss:0.22165\n[1100]\ttrain-logloss:0.19796\tvalid-logloss:0.22151\n[1200]\ttrain-logloss:0.19609\tvalid-logloss:0.22134\n[1300]\ttrain-logloss:0.19433\tvalid-logloss:0.22127\n[1400]\ttrain-logloss:0.19258\tvalid-logloss:0.22120\n[1500]\ttrain-logloss:0.19087\tvalid-logloss:0.22113\n[1600]\ttrain-logloss:0.18923\tvalid-logloss:0.22102\n[1700]\ttrain-logloss:0.18755\tvalid-logloss:0.22101\n[1800]\ttrain-logloss:0.18588\tvalid-logloss:0.22099\n[1860]\ttrain-logloss:0.18493\tvalid-logloss:0.22098\nKaggle Metric on valid set = 0.7850087008279395 \n\nKaggle Metric on all dataset = 0.8368959253908423 \n\n#########################\n### Fold 5\n### Train size 367131 Valid size 91782\n### Training with 100% fold data...\n#########################\n[0]\ttrain-logloss:0.66214\tvalid-logloss:0.66205\n[100]\ttrain-logloss:0.23829\tvalid-logloss:0.23863\n[200]\ttrain-logloss:0.22447\tvalid-logloss:0.22672\n[300]\ttrain-logloss:0.21877\tvalid-logloss:0.22284\n[400]\ttrain-logloss:0.21503\tvalid-logloss:0.22089\n[500]\ttrain-logloss:0.21208\tvalid-logloss:0.21981\n[600]\ttrain-logloss:0.20952\tvalid-logloss:0.21910\n[700]\ttrain-logloss:0.20720\tvalid-logloss:0.21857\n[800]\ttrain-logloss:0.20499\tvalid-logloss:0.21820\n[900]\ttrain-logloss:0.20294\tvalid-logloss:0.21793\n[1000]\ttrain-logloss:0.20095\tvalid-logloss:0.21772\n[1100]\ttrain-logloss:0.19908\tvalid-logloss:0.21757\n[1200]\ttrain-logloss:0.19725\tvalid-logloss:0.21747\n[1300]\ttrain-logloss:0.19545\tvalid-logloss:0.21731\n[1400]\ttrain-logloss:0.19375\tvalid-logloss:0.21715\n[1500]\ttrain-logloss:0.19202\tvalid-logloss:0.21704\n[1600]\ttrain-logloss:0.19031\tvalid-logloss:0.21696\n[1700]\ttrain-logloss:0.18871\tvalid-logloss:0.21693\n[1800]\ttrain-logloss:0.18704\tvalid-logloss:0.21692\n[1900]\ttrain-logloss:0.18545\tvalid-logloss:0.21689\n[2000]\ttrain-logloss:0.18387\tvalid-logloss:0.21682\n[2093]\ttrain-logloss:0.18243\tvalid-logloss:0.21683\nKaggle Metric on valid set = 0.7932108504595012 \n\nKaggle Metric on all dataset = 0.8420405751380446 \n\n#########################\nOVERALL CV Kaggle Metric = 0.7898008093050062\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## CateBoost","metadata":{}},{"cell_type":"code","source":"# GET CATEG VARIABLES\ncat_features = [\"B_30\", \"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\ncateg = []\n#print(train.columns)\nfor col in FEATURES_3 :\n    if col not in ['customer_ID', 'target'] :\n        VAR = '_'.join(col.split('_')[:2])\n        if VAR in cat_features :\n            categ.append(col)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:22:28.735915Z","iopub.execute_input":"2022-08-31T11:22:28.736963Z","iopub.status.idle":"2022-08-31T11:22:28.744027Z","shell.execute_reply.started":"2022-08-31T11:22:28.736925Z","shell.execute_reply":"2022-08-31T11:22:28.742922Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"oof = []\nskf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\nfor fold,(train_idx, valid_idx) in enumerate(skf.split(\n            train, train.target )):\n    print('#'*25)\n    print('### Fold',fold+1)\n    print('### Train size',len(train_idx),'Valid size',len(valid_idx))\n    print(f'### Training with {int(TRAIN_SUBSAMPLE*100)}% fold data...')\n    print('#'*25)\n    train_pool = Pool(train.loc[train_idx, FEATURES_3],\n                      train.loc[train_idx, 'target'],\n                      cat_features=categ\n                     )\n    valid_pool = Pool(train.loc[valid_idx, FEATURES_3],\n                      train.loc[valid_idx, 'target'],\n                      cat_features=categ\n                     )\n    model = CatBoostClassifier(iterations=9999,\n                               random_state=SEED,\n                               task_type=\"GPU\",\n                               loss_function = 'Logloss',\n                               learning_rate=0.05\n                               )\n    model.fit(train_pool, eval_set=valid_pool,\n              #od_type=\"Iter\",\n              early_stopping_rounds=100,\n              #od_wait=100,\n              verbose=100)\n    model.save_model(f'{ODIR}/CTB_dc0_features_v{VER}_fold{fold}.ctb')\n    valid_pred = model.predict_proba(valid_pool)[:,1]\n    val_acc = amex_metric_mod(train.loc[valid_idx, 'target'].values, valid_pred)\n    print('Kaggle Metric on valid set =',val_acc,'\\n')\n\n    df = train.loc[valid_idx, ['customer_ID','target'] ].copy()\n    df['oof_pred'] = valid_pred\n    oof.append( df )\n\n    del train_pool, valid_pool, df\n    _ = gc.collect()\n\n    all_pool = Pool(train[FEATURES_3],\n                    train['target'],\n                    cat_features=categ\n                     )\n    pred = model.predict_proba(all_pool)[:,1]\n    all_acc = amex_metric_mod(train['target'].values, pred)\n    print('Kaggle Metric on all dataset =',all_acc,'\\n')\n    #result_all = result_all.append({'model' : \"CateBoost\",\n    #                                'preprocessing' : \"huseyincot_dc0_feat\",\n    #                                'name' : f'CTB_dc0_features_v{VER}_fold{fold}',\n    #                                'y_valid_pred' : valid_pred,\n    #                                'valid_acc' : val_acc,\n    #                                'y_pred' : pred,\n    #                                'acc' : all_acc\n    #                               },\n    #                               ignore_index=True\n    #                              )\n    del all_pool, pred, valid_pred\n    _ = gc.collect()\n\nprint('#'*25)\noof = pd.concat(oof,axis=0,ignore_index=True).set_index('customer_ID')\nacc = amex_metric_mod(oof.target.values, oof.oof_pred.values)\n#result_sum = result_sum.append({'model' : \"CateBoost\",\n#                                'preprocessing':\"huseyincot_all_feat\",\n#                                'name' : \"CTB_huseyincot_all_feat\",\n#                                'y_pred' : oof,\n#                                'acc': acc\n#                               },\n#                               ignore_index=True\n#                              )\nprint('OVERALL CV Kaggle Metric =',acc)\n\ndel oof, acc\n_ = gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:22:28.745599Z","iopub.execute_input":"2022-08-31T11:22:28.746015Z","iopub.status.idle":"2022-08-31T11:34:24.800319Z","shell.execute_reply.started":"2022-08-31T11:22:28.74598Z","shell.execute_reply":"2022-08-31T11:34:24.799201Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"#########################\n### Fold 1\n### Train size 367130 Valid size 91783\n### Training with 100% fold data...\n#########################\n0:\tlearn: 0.6328783\ttest: 0.6328557\tbest: 0.6328557 (0)\ttotal: 38.8ms\tremaining: 6m 28s\n100:\tlearn: 0.2323115\ttest: 0.2343376\tbest: 0.2343376 (100)\ttotal: 3.88s\tremaining: 6m 20s\n200:\tlearn: 0.2249022\ttest: 0.2282003\tbest: 0.2282003 (200)\ttotal: 7.68s\tremaining: 6m 14s\n300:\tlearn: 0.2212112\ttest: 0.2256712\tbest: 0.2256712 (300)\ttotal: 11.8s\tremaining: 6m 19s\n400:\tlearn: 0.2187203\ttest: 0.2242778\tbest: 0.2242778 (400)\ttotal: 15.5s\tremaining: 6m 11s\n500:\tlearn: 0.2167083\ttest: 0.2234481\tbest: 0.2234481 (500)\ttotal: 20.6s\tremaining: 6m 30s\n600:\tlearn: 0.2149241\ttest: 0.2227717\tbest: 0.2227717 (600)\ttotal: 24.3s\tremaining: 6m 20s\n700:\tlearn: 0.2133364\ttest: 0.2223176\tbest: 0.2223176 (700)\ttotal: 28s\tremaining: 6m 11s\n800:\tlearn: 0.2118610\ttest: 0.2220234\tbest: 0.2220234 (800)\ttotal: 32.1s\tremaining: 6m 8s\n900:\tlearn: 0.2105219\ttest: 0.2217591\tbest: 0.2217591 (900)\ttotal: 35.8s\tremaining: 6m 1s\n1000:\tlearn: 0.2092255\ttest: 0.2215312\tbest: 0.2215312 (1000)\ttotal: 39.5s\tremaining: 5m 55s\n1100:\tlearn: 0.2079839\ttest: 0.2213734\tbest: 0.2213734 (1100)\ttotal: 43.7s\tremaining: 5m 52s\n1200:\tlearn: 0.2067052\ttest: 0.2211917\tbest: 0.2211917 (1200)\ttotal: 47.4s\tremaining: 5m 46s\n1300:\tlearn: 0.2055113\ttest: 0.2210461\tbest: 0.2210461 (1300)\ttotal: 52s\tremaining: 5m 47s\n1400:\tlearn: 0.2043721\ttest: 0.2209331\tbest: 0.2209326 (1399)\ttotal: 56.1s\tremaining: 5m 44s\n1500:\tlearn: 0.2031938\ttest: 0.2207362\tbest: 0.2207362 (1500)\ttotal: 59.8s\tremaining: 5m 38s\n1600:\tlearn: 0.2020223\ttest: 0.2206231\tbest: 0.2206231 (1600)\ttotal: 1m 3s\tremaining: 5m 35s\n1700:\tlearn: 0.2008618\ttest: 0.2205157\tbest: 0.2205157 (1700)\ttotal: 1m 7s\tremaining: 5m 29s\n1800:\tlearn: 0.1997315\ttest: 0.2204158\tbest: 0.2204113 (1795)\ttotal: 1m 11s\tremaining: 5m 24s\n1900:\tlearn: 0.1986916\ttest: 0.2203573\tbest: 0.2203565 (1898)\ttotal: 1m 15s\tremaining: 5m 20s\n2000:\tlearn: 0.1976815\ttest: 0.2202611\tbest: 0.2202577 (1998)\ttotal: 1m 18s\tremaining: 5m 15s\n2100:\tlearn: 0.1966112\ttest: 0.2201603\tbest: 0.2201603 (2100)\ttotal: 1m 23s\tremaining: 5m 12s\n2200:\tlearn: 0.1955696\ttest: 0.2200550\tbest: 0.2200550 (2200)\ttotal: 1m 27s\tremaining: 5m 10s\n2300:\tlearn: 0.1945450\ttest: 0.2199959\tbest: 0.2199959 (2300)\ttotal: 1m 31s\tremaining: 5m 5s\n2400:\tlearn: 0.1935274\ttest: 0.2199290\tbest: 0.2199244 (2398)\ttotal: 1m 35s\tremaining: 5m\n2500:\tlearn: 0.1925161\ttest: 0.2198683\tbest: 0.2198683 (2500)\ttotal: 1m 39s\tremaining: 4m 57s\n2600:\tlearn: 0.1915370\ttest: 0.2198132\tbest: 0.2198068 (2579)\ttotal: 1m 42s\tremaining: 4m 52s\n2700:\tlearn: 0.1905549\ttest: 0.2197339\tbest: 0.2197333 (2697)\ttotal: 1m 46s\tremaining: 4m 47s\n2800:\tlearn: 0.1895090\ttest: 0.2196786\tbest: 0.2196754 (2799)\ttotal: 1m 50s\tremaining: 4m 44s\n2900:\tlearn: 0.1885330\ttest: 0.2196210\tbest: 0.2196131 (2895)\ttotal: 1m 55s\tremaining: 4m 41s\n3000:\tlearn: 0.1875565\ttest: 0.2195343\tbest: 0.2195334 (2995)\ttotal: 1m 59s\tremaining: 4m 39s\n3100:\tlearn: 0.1866086\ttest: 0.2194620\tbest: 0.2194620 (3100)\ttotal: 2m 3s\tremaining: 4m 35s\n3200:\tlearn: 0.1856968\ttest: 0.2193975\tbest: 0.2193945 (3198)\ttotal: 2m 7s\tremaining: 4m 30s\n3300:\tlearn: 0.1847398\ttest: 0.2193747\tbest: 0.2193682 (3269)\ttotal: 2m 11s\tremaining: 4m 26s\n3400:\tlearn: 0.1838162\ttest: 0.2193719\tbest: 0.2193635 (3345)\ttotal: 2m 15s\tremaining: 4m 22s\nbestTest = 0.2193634757\nbestIteration = 3345\nShrink model to first 3346 iterations.\nKaggle Metric on valid set = 0.7902843519806662 \n\nKaggle Metric on all dataset = 0.8462050835285264 \n\n#########################\n### Fold 2\n### Train size 367130 Valid size 91783\n### Training with 100% fold data...\n#########################\n0:\tlearn: 0.6329857\ttest: 0.6328961\tbest: 0.6328961 (0)\ttotal: 41ms\tremaining: 6m 49s\n100:\tlearn: 0.2325576\ttest: 0.2324507\tbest: 0.2324507 (100)\ttotal: 3.9s\tremaining: 6m 21s\n200:\tlearn: 0.2252855\ttest: 0.2262798\tbest: 0.2262798 (200)\ttotal: 8.1s\tremaining: 6m 34s\n300:\tlearn: 0.2216618\ttest: 0.2238752\tbest: 0.2238752 (300)\ttotal: 11.9s\tremaining: 6m 22s\n400:\tlearn: 0.2190571\ttest: 0.2225592\tbest: 0.2225592 (400)\ttotal: 15.6s\tremaining: 6m 13s\n500:\tlearn: 0.2169624\ttest: 0.2217515\tbest: 0.2217515 (500)\ttotal: 19.9s\tremaining: 6m 16s\n600:\tlearn: 0.2152191\ttest: 0.2212530\tbest: 0.2212530 (600)\ttotal: 24.7s\tremaining: 6m 25s\n700:\tlearn: 0.2135742\ttest: 0.2207753\tbest: 0.2207736 (699)\ttotal: 28.8s\tremaining: 6m 22s\n800:\tlearn: 0.2120956\ttest: 0.2203854\tbest: 0.2203854 (800)\ttotal: 32.6s\tremaining: 6m 14s\n900:\tlearn: 0.2107033\ttest: 0.2201343\tbest: 0.2201331 (899)\ttotal: 36.3s\tremaining: 6m 6s\n1000:\tlearn: 0.2094288\ttest: 0.2199649\tbest: 0.2199649 (1000)\ttotal: 40.4s\tremaining: 6m 3s\n1100:\tlearn: 0.2081867\ttest: 0.2197858\tbest: 0.2197835 (1097)\ttotal: 44.1s\tremaining: 5m 56s\n1200:\tlearn: 0.2069042\ttest: 0.2196448\tbest: 0.2196425 (1199)\ttotal: 47.8s\tremaining: 5m 50s\n1300:\tlearn: 0.2056189\ttest: 0.2194456\tbest: 0.2194456 (1300)\ttotal: 52.1s\tremaining: 5m 48s\n1400:\tlearn: 0.2044127\ttest: 0.2193394\tbest: 0.2193368 (1399)\ttotal: 56.9s\tremaining: 5m 48s\n1500:\tlearn: 0.2032199\ttest: 0.2192320\tbest: 0.2192320 (1500)\ttotal: 1m\tremaining: 5m 42s\n1600:\tlearn: 0.2021283\ttest: 0.2191461\tbest: 0.2191461 (1600)\ttotal: 1m 4s\tremaining: 5m 39s\n1700:\tlearn: 0.2010541\ttest: 0.2190843\tbest: 0.2190843 (1700)\ttotal: 1m 8s\tremaining: 5m 33s\n1800:\tlearn: 0.1999202\ttest: 0.2189884\tbest: 0.2189845 (1798)\ttotal: 1m 12s\tremaining: 5m 28s\n1900:\tlearn: 0.1988566\ttest: 0.2189093\tbest: 0.2189055 (1885)\ttotal: 1m 16s\tremaining: 5m 26s\n2000:\tlearn: 0.1977379\ttest: 0.2188100\tbest: 0.2188100 (2000)\ttotal: 1m 20s\tremaining: 5m 20s\n2100:\tlearn: 0.1966898\ttest: 0.2187455\tbest: 0.2187450 (2097)\ttotal: 1m 24s\tremaining: 5m 16s\n2200:\tlearn: 0.1956775\ttest: 0.2186913\tbest: 0.2186908 (2198)\ttotal: 1m 28s\tremaining: 5m 14s\n2300:\tlearn: 0.1946257\ttest: 0.2186305\tbest: 0.2186261 (2272)\ttotal: 1m 32s\tremaining: 5m 9s\n2400:\tlearn: 0.1935655\ttest: 0.2185734\tbest: 0.2185649 (2389)\ttotal: 1m 36s\tremaining: 5m 5s\n2500:\tlearn: 0.1925672\ttest: 0.2185357\tbest: 0.2185190 (2483)\ttotal: 1m 40s\tremaining: 5m\n2600:\tlearn: 0.1915761\ttest: 0.2184599\tbest: 0.2184599 (2600)\ttotal: 1m 43s\tremaining: 4m 55s\n2700:\tlearn: 0.1905942\ttest: 0.2184563\tbest: 0.2184535 (2605)\ttotal: 1m 47s\tremaining: 4m 51s\nbestTest = 0.2184535297\nbestIteration = 2605\nShrink model to first 2606 iterations.\nKaggle Metric on valid set = 0.7909287263468499 \n\nKaggle Metric on all dataset = 0.8352804202045883 \n\n#########################\n### Fold 3\n### Train size 367130 Valid size 91783\n### Training with 100% fold data...\n#########################\n0:\tlearn: 0.6326420\ttest: 0.6327865\tbest: 0.6327865 (0)\ttotal: 41.6ms\tremaining: 6m 56s\n100:\tlearn: 0.2322087\ttest: 0.2352145\tbest: 0.2352145 (100)\ttotal: 4.33s\tremaining: 7m 4s\n200:\tlearn: 0.2247245\ttest: 0.2291515\tbest: 0.2291515 (200)\ttotal: 8.1s\tremaining: 6m 34s\n300:\tlearn: 0.2209887\ttest: 0.2267766\tbest: 0.2267766 (300)\ttotal: 12s\tremaining: 6m 26s\n400:\tlearn: 0.2183528\ttest: 0.2254968\tbest: 0.2254968 (400)\ttotal: 16s\tremaining: 6m 23s\n500:\tlearn: 0.2162755\ttest: 0.2247287\tbest: 0.2247287 (500)\ttotal: 19.7s\tremaining: 6m 13s\n600:\tlearn: 0.2146235\ttest: 0.2242414\tbest: 0.2242414 (600)\ttotal: 23.8s\tremaining: 6m 11s\n700:\tlearn: 0.2130063\ttest: 0.2238412\tbest: 0.2238412 (700)\ttotal: 28.4s\tremaining: 6m 16s\n800:\tlearn: 0.2116650\ttest: 0.2235902\tbest: 0.2235902 (800)\ttotal: 32.1s\tremaining: 6m 8s\n900:\tlearn: 0.2102383\ttest: 0.2232911\tbest: 0.2232911 (900)\ttotal: 36.2s\tremaining: 6m 5s\n1000:\tlearn: 0.2089155\ttest: 0.2230398\tbest: 0.2230398 (1000)\ttotal: 39.9s\tremaining: 5m 58s\n1100:\tlearn: 0.2076652\ttest: 0.2228729\tbest: 0.2228729 (1100)\ttotal: 43.5s\tremaining: 5m 51s\n1200:\tlearn: 0.2063171\ttest: 0.2227424\tbest: 0.2227350 (1193)\ttotal: 47.5s\tremaining: 5m 48s\n1300:\tlearn: 0.2050659\ttest: 0.2226553\tbest: 0.2226539 (1299)\ttotal: 51.2s\tremaining: 5m 42s\n1400:\tlearn: 0.2039387\ttest: 0.2225412\tbest: 0.2225357 (1396)\ttotal: 54.9s\tremaining: 5m 36s\n1500:\tlearn: 0.2028173\ttest: 0.2224409\tbest: 0.2224343 (1496)\ttotal: 59.9s\tremaining: 5m 39s\n1600:\tlearn: 0.2016083\ttest: 0.2223129\tbest: 0.2223129 (1600)\ttotal: 1m 3s\tremaining: 5m 33s\n1700:\tlearn: 0.2005265\ttest: 0.2222030\tbest: 0.2221986 (1693)\ttotal: 1m 7s\tremaining: 5m 30s\n1800:\tlearn: 0.1994177\ttest: 0.2221546\tbest: 0.2221459 (1791)\ttotal: 1m 11s\tremaining: 5m 26s\n1900:\tlearn: 0.1983874\ttest: 0.2220937\tbest: 0.2220930 (1899)\ttotal: 1m 15s\tremaining: 5m 21s\n2000:\tlearn: 0.1973453\ttest: 0.2220232\tbest: 0.2220199 (1994)\ttotal: 1m 19s\tremaining: 5m 17s\n2100:\tlearn: 0.1962243\ttest: 0.2219656\tbest: 0.2219582 (2088)\ttotal: 1m 23s\tremaining: 5m 13s\n2200:\tlearn: 0.1951822\ttest: 0.2219191\tbest: 0.2219191 (2200)\ttotal: 1m 26s\tremaining: 5m 8s\n2300:\tlearn: 0.1941501\ttest: 0.2218517\tbest: 0.2218377 (2292)\ttotal: 1m 31s\tremaining: 5m 7s\n2400:\tlearn: 0.1931325\ttest: 0.2217693\tbest: 0.2217658 (2395)\ttotal: 1m 35s\tremaining: 5m 2s\n2500:\tlearn: 0.1921561\ttest: 0.2216909\tbest: 0.2216906 (2499)\ttotal: 1m 39s\tremaining: 4m 57s\n2600:\tlearn: 0.1911664\ttest: 0.2216264\tbest: 0.2216264 (2600)\ttotal: 1m 43s\tremaining: 4m 54s\n2700:\tlearn: 0.1901386\ttest: 0.2215591\tbest: 0.2215511 (2672)\ttotal: 1m 47s\tremaining: 4m 49s\n2800:\tlearn: 0.1891929\ttest: 0.2214587\tbest: 0.2214587 (2799)\ttotal: 1m 50s\tremaining: 4m 44s\n2900:\tlearn: 0.1882277\ttest: 0.2214161\tbest: 0.2214108 (2892)\ttotal: 1m 54s\tremaining: 4m 40s\n3000:\tlearn: 0.1872825\ttest: 0.2214212\tbest: 0.2213974 (2958)\ttotal: 1m 58s\tremaining: 4m 35s\nbestTest = 0.2213973789\nbestIteration = 2958\nShrink model to first 2959 iterations.\nKaggle Metric on valid set = 0.7886045336530274 \n\nKaggle Metric on all dataset = 0.8401038538527388 \n\n#########################\n### Fold 4\n### Train size 367131 Valid size 91782\n### Training with 100% fold data...\n#########################\n0:\tlearn: 0.6327105\ttest: 0.6329225\tbest: 0.6329225 (0)\ttotal: 41.7ms\tremaining: 6m 56s\n100:\tlearn: 0.2320197\ttest: 0.2350136\tbest: 0.2350136 (100)\ttotal: 3.92s\tremaining: 6m 24s\n200:\tlearn: 0.2247153\ttest: 0.2289905\tbest: 0.2289905 (200)\ttotal: 8.16s\tremaining: 6m 37s\n300:\tlearn: 0.2208744\ttest: 0.2265737\tbest: 0.2265737 (300)\ttotal: 11.9s\tremaining: 6m 24s\n400:\tlearn: 0.2182449\ttest: 0.2253053\tbest: 0.2253053 (400)\ttotal: 17.3s\tremaining: 6m 54s\n500:\tlearn: 0.2162344\ttest: 0.2245870\tbest: 0.2245870 (500)\ttotal: 21.1s\tremaining: 6m 39s\n600:\tlearn: 0.2145393\ttest: 0.2240802\tbest: 0.2240802 (600)\ttotal: 24.8s\tremaining: 6m 27s\n700:\tlearn: 0.2129797\ttest: 0.2236825\tbest: 0.2236808 (695)\ttotal: 28.9s\tremaining: 6m 23s\n800:\tlearn: 0.2114793\ttest: 0.2233142\tbest: 0.2233142 (800)\ttotal: 32.6s\tremaining: 6m 14s\n900:\tlearn: 0.2101247\ttest: 0.2230490\tbest: 0.2230490 (900)\ttotal: 36.3s\tremaining: 6m 6s\n1000:\tlearn: 0.2088702\ttest: 0.2228447\tbest: 0.2228415 (998)\ttotal: 40.4s\tremaining: 6m 3s\n1100:\tlearn: 0.2075581\ttest: 0.2226351\tbest: 0.2226351 (1100)\ttotal: 44.2s\tremaining: 5m 56s\n1200:\tlearn: 0.2062835\ttest: 0.2225021\tbest: 0.2224987 (1195)\ttotal: 48.9s\tremaining: 5m 58s\n1300:\tlearn: 0.2049743\ttest: 0.2223124\tbest: 0.2223124 (1300)\ttotal: 53.1s\tremaining: 5m 54s\n1400:\tlearn: 0.2037977\ttest: 0.2222420\tbest: 0.2222380 (1374)\ttotal: 56.7s\tremaining: 5m 48s\n1500:\tlearn: 0.2025995\ttest: 0.2221258\tbest: 0.2221191 (1498)\ttotal: 1m\tremaining: 5m 43s\n1600:\tlearn: 0.2015268\ttest: 0.2220339\tbest: 0.2220339 (1600)\ttotal: 1m 4s\tremaining: 5m 37s\n1700:\tlearn: 0.2004315\ttest: 0.2219718\tbest: 0.2219694 (1697)\ttotal: 1m 8s\tremaining: 5m 32s\n1800:\tlearn: 0.1993099\ttest: 0.2219354\tbest: 0.2219286 (1780)\ttotal: 1m 12s\tremaining: 5m 28s\n1900:\tlearn: 0.1982034\ttest: 0.2218764\tbest: 0.2218718 (1898)\ttotal: 1m 15s\tremaining: 5m 23s\n2000:\tlearn: 0.1971119\ttest: 0.2218189\tbest: 0.2218189 (2000)\ttotal: 1m 20s\tremaining: 5m 21s\n2100:\tlearn: 0.1960745\ttest: 0.2217441\tbest: 0.2217376 (2095)\ttotal: 1m 24s\tremaining: 5m 17s\n2200:\tlearn: 0.1950161\ttest: 0.2216666\tbest: 0.2216654 (2199)\ttotal: 1m 28s\tremaining: 5m 12s\n2300:\tlearn: 0.1940159\ttest: 0.2216178\tbest: 0.2216006 (2286)\ttotal: 1m 31s\tremaining: 5m 7s\n2400:\tlearn: 0.1929468\ttest: 0.2215625\tbest: 0.2215419 (2352)\ttotal: 1m 36s\tremaining: 5m 3s\n2500:\tlearn: 0.1919566\ttest: 0.2214652\tbest: 0.2214652 (2500)\ttotal: 1m 39s\tremaining: 4m 59s\n2600:\tlearn: 0.1909360\ttest: 0.2214473\tbest: 0.2214305 (2594)\ttotal: 1m 43s\tremaining: 4m 54s\n2700:\tlearn: 0.1899429\ttest: 0.2213670\tbest: 0.2213670 (2700)\ttotal: 1m 47s\tremaining: 4m 50s\n2800:\tlearn: 0.1889102\ttest: 0.2213145\tbest: 0.2213086 (2787)\ttotal: 1m 52s\tremaining: 4m 48s\n2900:\tlearn: 0.1879947\ttest: 0.2212773\tbest: 0.2212773 (2900)\ttotal: 1m 56s\tremaining: 4m 44s\n3000:\tlearn: 0.1870399\ttest: 0.2212567\tbest: 0.2212567 (3000)\ttotal: 2m\tremaining: 4m 40s\n3100:\tlearn: 0.1860642\ttest: 0.2212032\tbest: 0.2212032 (3100)\ttotal: 2m 3s\tremaining: 4m 35s\n3200:\tlearn: 0.1851409\ttest: 0.2211516\tbest: 0.2211445 (3182)\ttotal: 2m 7s\tremaining: 4m 31s\n3300:\tlearn: 0.1841466\ttest: 0.2211098\tbest: 0.2211086 (3248)\ttotal: 2m 11s\tremaining: 4m 27s\n3400:\tlearn: 0.1832134\ttest: 0.2211015\tbest: 0.2210835 (3377)\ttotal: 2m 15s\tremaining: 4m 22s\nbestTest = 0.2210834845\nbestIteration = 3377\nShrink model to first 3378 iterations.\nKaggle Metric on valid set = 0.7847960013636451 \n\nKaggle Metric on all dataset = 0.8469209646734932 \n\n#########################\n### Fold 5\n### Train size 367131 Valid size 91782\n### Training with 100% fold data...\n#########################\n0:\tlearn: 0.6339732\ttest: 0.6338982\tbest: 0.6338982 (0)\ttotal: 41.4ms\tremaining: 6m 54s\n100:\tlearn: 0.2328886\ttest: 0.2325349\tbest: 0.2325349 (100)\ttotal: 4.24s\tremaining: 6m 55s\n200:\tlearn: 0.2255965\ttest: 0.2260462\tbest: 0.2260462 (200)\ttotal: 8.04s\tremaining: 6m 31s\n300:\tlearn: 0.2217889\ttest: 0.2232282\tbest: 0.2232282 (300)\ttotal: 11.8s\tremaining: 6m 20s\n400:\tlearn: 0.2192541\ttest: 0.2218812\tbest: 0.2218812 (400)\ttotal: 16.3s\tremaining: 6m 30s\n500:\tlearn: 0.2172945\ttest: 0.2210584\tbest: 0.2210584 (500)\ttotal: 20.8s\tremaining: 6m 34s\n600:\tlearn: 0.2154541\ttest: 0.2203878\tbest: 0.2203878 (600)\ttotal: 25s\tremaining: 6m 30s\n700:\tlearn: 0.2138547\ttest: 0.2198906\tbest: 0.2198898 (699)\ttotal: 28.7s\tremaining: 6m 20s\n800:\tlearn: 0.2124069\ttest: 0.2196115\tbest: 0.2196115 (800)\ttotal: 32.4s\tremaining: 6m 12s\n900:\tlearn: 0.2110359\ttest: 0.2193505\tbest: 0.2193505 (900)\ttotal: 36.5s\tremaining: 6m 8s\n1000:\tlearn: 0.2097669\ttest: 0.2191025\tbest: 0.2191015 (999)\ttotal: 40.2s\tremaining: 6m 1s\n1100:\tlearn: 0.2085336\ttest: 0.2189123\tbest: 0.2189123 (1100)\ttotal: 43.9s\tremaining: 5m 55s\n1200:\tlearn: 0.2072259\ttest: 0.2187268\tbest: 0.2187268 (1200)\ttotal: 48.1s\tremaining: 5m 52s\n1300:\tlearn: 0.2060687\ttest: 0.2185252\tbest: 0.2185252 (1300)\ttotal: 52.6s\tremaining: 5m 51s\n1400:\tlearn: 0.2048856\ttest: 0.2184332\tbest: 0.2184259 (1376)\ttotal: 56.5s\tremaining: 5m 46s\n1500:\tlearn: 0.2037424\ttest: 0.2183199\tbest: 0.2183199 (1500)\ttotal: 1m\tremaining: 5m 41s\n1600:\tlearn: 0.2026178\ttest: 0.2182508\tbest: 0.2182471 (1597)\ttotal: 1m 4s\tremaining: 5m 36s\n1700:\tlearn: 0.2015193\ttest: 0.2181822\tbest: 0.2181822 (1700)\ttotal: 1m 8s\tremaining: 5m 32s\n1800:\tlearn: 0.2004267\ttest: 0.2181113\tbest: 0.2181113 (1800)\ttotal: 1m 11s\tremaining: 5m 27s\n1900:\tlearn: 0.1993165\ttest: 0.2180537\tbest: 0.2180445 (1889)\ttotal: 1m 15s\tremaining: 5m 22s\n2000:\tlearn: 0.1982386\ttest: 0.2179518\tbest: 0.2179518 (2000)\ttotal: 1m 19s\tremaining: 5m 19s\n2100:\tlearn: 0.1971727\ttest: 0.2178795\tbest: 0.2178746 (2065)\ttotal: 1m 24s\tremaining: 5m 17s\n2200:\tlearn: 0.1961333\ttest: 0.2177965\tbest: 0.2177956 (2186)\ttotal: 1m 28s\tremaining: 5m 12s\n2300:\tlearn: 0.1950842\ttest: 0.2177598\tbest: 0.2177552 (2275)\ttotal: 1m 32s\tremaining: 5m 9s\n2400:\tlearn: 0.1940418\ttest: 0.2177287\tbest: 0.2177157 (2381)\ttotal: 1m 36s\tremaining: 5m 4s\n2500:\tlearn: 0.1930437\ttest: 0.2176770\tbest: 0.2176720 (2499)\ttotal: 1m 39s\tremaining: 4m 59s\n2600:\tlearn: 0.1920695\ttest: 0.2176572\tbest: 0.2176472 (2595)\ttotal: 1m 44s\tremaining: 4m 56s\n2700:\tlearn: 0.1911101\ttest: 0.2175914\tbest: 0.2175850 (2699)\ttotal: 1m 47s\tremaining: 4m 51s\n2800:\tlearn: 0.1901184\ttest: 0.2175506\tbest: 0.2175424 (2773)\ttotal: 1m 51s\tremaining: 4m 47s\n2900:\tlearn: 0.1891559\ttest: 0.2175462\tbest: 0.2175330 (2851)\ttotal: 1m 56s\tremaining: 4m 45s\nbestTest = 0.2175329943\nbestIteration = 2851\nShrink model to first 2852 iterations.\nKaggle Metric on valid set = 0.794260894125677 \n\nKaggle Metric on all dataset = 0.8388029437136577 \n\n#########################\nOVERALL CV Kaggle Metric = 0.7898946134300707\n","output_type":"stream"}]},{"cell_type":"code","source":"del train\n_=gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T11:34:24.80196Z","iopub.execute_input":"2022-08-31T11:34:24.802368Z","iopub.status.idle":"2022-08-31T11:34:25.007691Z","shell.execute_reply.started":"2022-08-31T11:34:24.802332Z","shell.execute_reply":"2022-08-31T11:34:25.006355Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"All Model should be download in order to be used in \nanother notebook to create the submission file.","metadata":{}}]}